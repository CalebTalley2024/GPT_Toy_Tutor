{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-01-11T20:17:37.174418100Z",
     "start_time": "2024-01-11T20:17:27.116320400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n",
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "# from dotenv import load_dotenv\n",
    "#TODO use dotenv file when you release final version\n",
    "import json\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# import custom python files for memory and students functions\n",
    "import Memory\n",
    "import students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T20:17:39.153341400Z",
     "start_time": "2024-01-11T20:17:39.077291800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Grade Education Level                                      Math Topic   \n0        1      Elementary                                Counting numbers  \\\n1        1      Elementary                               Comparing numbers   \n2        1      Elementary                              Addition within 20   \n3        1      Elementary                           Subtraction within 20   \n4        1      Elementary                          Place value within 100   \n..     ...             ...                                             ...   \n121     12     High School          Trigonometric identities and equations   \n122     12     High School                   Analytic geometry and vectors   \n123     12     High School                      Probability and statistics   \n124     12     High School                                        Calculus   \n125     12     High School  Discrete mathematics and financial mathematics   \n\n                               Sub_topic_1   \n0                         Counting objects  \\\n1          Comparing numbers using symbols   \n2              Addition without regrouping   \n3           Subtraction without regrouping   \n4             Place value of tens and ones   \n..                                     ...   \n121       Proving trigonometric identities   \n122     Lines, planes, and their equations   \n123     Probability rules and calculations   \n124                  Limits and continuity   \n125  Combinatorics and counting principles   \n\n                                          Sub_topic_2   \n0                       Counting forward and backward  \\\n1                     Comparing numbers using objects   \n2                            Addition with regrouping   \n3                         Subtraction with regrouping   \n4                  Expanded form of two-digit numbers   \n..                                                ...   \n121  Solving trigonometric equations and inequalities   \n122                  Vector operations and properties   \n123          Discrete and continuous random variables   \n124                Derivatives and their applications   \n125                         Graph theory and networks   \n\n                                         Sub_topic_3   \n0                         Skip counting by 2s and 5s  \\\n1                                  Comparing numbers   \n2                        Word problems with addition   \n3                     Word problems with subtraction   \n4                        Comparing two-digit numbers   \n..                                               ...   \n121           Complex numbers and their applications   \n122  Applications of vectors in geometry and physics   \n123          Statistical data analysis and inference   \n124                 Integrals and their applications   \n125            Financial mathematics and investments   \n\n                                     Sub_topic_4   \n0                 Counting in different patterns  \\\n1                           Comparing quantities   \n2                           Adding three numbers   \n3                Subtracting from a given number   \n4                 Skip counting in tens and ones   \n..                                           ...   \n121        Modeling with trigonometric functions   \n122       Three-dimensional geometry and vectors   \n123  Hypothesis testing and confidence intervals   \n124          Differential equations and modeling   \n125          Optimization and linear programming   \n\n                                           Sub_topic_5  \n0                            Counting on a number line  \n1                                     Comparing values  \n2                           Solving addition equations  \n3                        Solving subtraction equations  \n4                                 Representing numbers  \n..                                                 ...  \n121                  Differential equations and series  \n122  Dot product, cross product, and their applicat...  \n123                Regression analysis and correlation  \n124         Multivariable calculus and vector calculus  \n125                     Cryptography and coding theory  \n\n[126 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Grade</th>\n      <th>Education Level</th>\n      <th>Math Topic</th>\n      <th>Sub_topic_1</th>\n      <th>Sub_topic_2</th>\n      <th>Sub_topic_3</th>\n      <th>Sub_topic_4</th>\n      <th>Sub_topic_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Elementary</td>\n      <td>Counting numbers</td>\n      <td>Counting objects</td>\n      <td>Counting forward and backward</td>\n      <td>Skip counting by 2s and 5s</td>\n      <td>Counting in different patterns</td>\n      <td>Counting on a number line</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Elementary</td>\n      <td>Comparing numbers</td>\n      <td>Comparing numbers using symbols</td>\n      <td>Comparing numbers using objects</td>\n      <td>Comparing numbers</td>\n      <td>Comparing quantities</td>\n      <td>Comparing values</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Elementary</td>\n      <td>Addition within 20</td>\n      <td>Addition without regrouping</td>\n      <td>Addition with regrouping</td>\n      <td>Word problems with addition</td>\n      <td>Adding three numbers</td>\n      <td>Solving addition equations</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Elementary</td>\n      <td>Subtraction within 20</td>\n      <td>Subtraction without regrouping</td>\n      <td>Subtraction with regrouping</td>\n      <td>Word problems with subtraction</td>\n      <td>Subtracting from a given number</td>\n      <td>Solving subtraction equations</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Elementary</td>\n      <td>Place value within 100</td>\n      <td>Place value of tens and ones</td>\n      <td>Expanded form of two-digit numbers</td>\n      <td>Comparing two-digit numbers</td>\n      <td>Skip counting in tens and ones</td>\n      <td>Representing numbers</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>12</td>\n      <td>High School</td>\n      <td>Trigonometric identities and equations</td>\n      <td>Proving trigonometric identities</td>\n      <td>Solving trigonometric equations and inequalities</td>\n      <td>Complex numbers and their applications</td>\n      <td>Modeling with trigonometric functions</td>\n      <td>Differential equations and series</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>12</td>\n      <td>High School</td>\n      <td>Analytic geometry and vectors</td>\n      <td>Lines, planes, and their equations</td>\n      <td>Vector operations and properties</td>\n      <td>Applications of vectors in geometry and physics</td>\n      <td>Three-dimensional geometry and vectors</td>\n      <td>Dot product, cross product, and their applicat...</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>12</td>\n      <td>High School</td>\n      <td>Probability and statistics</td>\n      <td>Probability rules and calculations</td>\n      <td>Discrete and continuous random variables</td>\n      <td>Statistical data analysis and inference</td>\n      <td>Hypothesis testing and confidence intervals</td>\n      <td>Regression analysis and correlation</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>12</td>\n      <td>High School</td>\n      <td>Calculus</td>\n      <td>Limits and continuity</td>\n      <td>Derivatives and their applications</td>\n      <td>Integrals and their applications</td>\n      <td>Differential equations and modeling</td>\n      <td>Multivariable calculus and vector calculus</td>\n    </tr>\n    <tr>\n      <th>125</th>\n      <td>12</td>\n      <td>High School</td>\n      <td>Discrete mathematics and financial mathematics</td>\n      <td>Combinatorics and counting principles</td>\n      <td>Graph theory and networks</td>\n      <td>Financial mathematics and investments</td>\n      <td>Optimization and linear programming</td>\n      <td>Cryptography and coding theory</td>\n    </tr>\n  </tbody>\n</table>\n<p>126 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get syllabus\n",
    "# df1 = pd.read_csv('topics.csv')\n",
    "df2 = pd.read_csv('../data/GPT_tutor_topics(sub_topics_included).csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T20:17:43.516421500Z",
     "start_time": "2024-01-11T20:17:43.484366600Z"
    }
   },
   "outputs": [],
   "source": [
    "# get key and model\n",
    "openai.api_key = \"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\"\n",
    "model_35 = \"gpt-3.5-turbo\"\n",
    "student_data_path = \"../data/students.json\"\n",
    "memory_path = \"../data/memory.json\"\n",
    "question_temp = 1 # temp has to be between 0 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T20:17:44.039583500Z",
     "start_time": "2024-01-11T20:17:43.981410200Z"
    }
   },
   "outputs": [],
   "source": [
    "# data helper functions for JSON data\n",
    "# getting external data\n",
    "def get_ext_data(path):\n",
    "    with open(path, \"r\") as file:\n",
    "        database = json.load(file)\n",
    "    return database\n",
    "\n",
    "# post/update at the external data path\n",
    "def post_ext_data(data, path):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# helper functions\n",
    "# API responses\n",
    "def get_response(messages):\n",
    "    res = openai.ChatCompletion.create(\n",
    "        model = model_35,\n",
    "        messages = messages,\n",
    "        temperature = 0 # make sure responses are deterministic/consistent\n",
    "    )\n",
    "    return res\n",
    "def get_response_text(messages):\n",
    "    res = get_response(messages)\n",
    "    return res['choices'][0]['message']['content']\n",
    "# be able to get the response and edit temperature\n",
    "def get_response_text_w_temp(messages, temp):\n",
    "    res = openai.ChatCompletion.create(\n",
    "        model = model_35,\n",
    "        messages = messages,\n",
    "        temperature = temp # make sure responses are deterministic/consistent\n",
    "    )\n",
    "    return res['choices'][0]['message']['content']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:17:44.508895600Z",
     "start_time": "2024-01-11T20:17:44.487332700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# creates one part of the message that you send to the GPT API for a response.\n",
    "# add brackets [] if you want to use this function to make a full message\n",
    "# System: 1\n",
    "# Assistant: 2\n",
    "# User: 3\n",
    "def create_message_part(text, role_type):\n",
    "    role = None\n",
    "    if role_type == 1:\n",
    "        role = \"system\"\n",
    "    elif role_type == 2:\n",
    "        role = \"assistant\"\n",
    "    elif role_type == 3:\n",
    "        role = \"user\"\n",
    "    message_part = {\n",
    "        \"role\": role,\n",
    "        \"content\": text\n",
    "    }\n",
    "    return message_part"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:17:44.931336100Z",
     "start_time": "2024-01-11T20:17:44.906193800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# helper functions for ask_question\n",
    "# database is currently 'students.json'\n",
    "# 1. make sure GPT only answers math questions\n",
    "def filter_answers():\n",
    "    message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"I am a math teacher for Grade K-12 in the United States. I am using the GPT API to help me answer my students' math questions. Please only answer my questions about math, and do not respond to any questions that are not about math.\"\n",
    "    }\n",
    "    return message\n",
    "# is_current_student: boolean\n",
    "def init_question(student, subtopic, user_type):\n",
    "\n",
    "    # Prompt for level choice\n",
    "    if user_type == \"user\":\n",
    "        print(\"Hello User/Student! \\npicking the level manually will only affect the type of questions you get\")\n",
    "        choice = input(\"Do you want to pick the level? (Y/N): \")\n",
    "    elif user_type == \"trainer\":\n",
    "        print(\"Hello Trainer. \\n Since you are training GPT_Tutor, you will be able to pick the level of the question that you get\")\n",
    "        choice = \"Y\"\n",
    "    else:\n",
    "        print(\"Invalid input\")\n",
    "\n",
    "    # If statement based on the choice\n",
    "    if choice.upper() == \"Y\":\n",
    "        valid = True\n",
    "        while valid:\n",
    "                custom_level = int(input(\"Enter the level you want between 1 and 5: \"))\n",
    "                if custom_level > 5 or custom_level < 1:\n",
    "                    print(\"Invalid level, pick again.\")\n",
    "                else:\n",
    "                    valid = False\n",
    "                    # Reset student's level if needed\n",
    "                    subtopic.level = custom_level\n",
    "                \n",
    "    # criteria: tell GPT scales for proficiency and level\n",
    "    init = f\"Based on {student}'s database, the student's skill level for {subtopic.name} is {subtopic.level}. Please give {student} a test question based on {subtopic.name} and follow up with a sentence like 'Explain how you got your answer'. Adjust the difficulty of the question based on his skill level and proficiency score. DO NOT include any other words. Do not put the answer in the prompt.\"\n",
    "    criteria = f\"Level is on a scale between 1 and 5, where 5 is the hardest level.\"\n",
    "\n",
    "    # combine criteria and message\n",
    "    message = f\"{init} {criteria}\"\n",
    "    init_crit = create_message_part(message,1) # create system message\n",
    "\n",
    "    return init_crit\n",
    "# changes the format of the question GPT gives\n",
    "def question_formatting():\n",
    "    init = \"\"\"\n",
    "    This is the format that you should be using\n",
    "\n",
    "    \"\"\"\n",
    "    format = \"\"\"\n",
    "        Level 1 (Difficulty: Easy):\n",
    "        Subtract the following without regrouping (no borrowing):\n",
    "\n",
    "        1. 46-19\n",
    "\n",
    "    \"\"\"\n",
    "    level_meaning = \"\"\"\n",
    "    Remember the description that follows each Level\n",
    "\n",
    "    Level 1 (Difficulty: Easy):\n",
    "\n",
    "    Level 2 (Difficulty: Easy-Moderate):\n",
    "\n",
    "    Level 3 (Difficulty: Moderate):\n",
    "\n",
    "    Level 4 (Difficulty: Moderate-Hard):\n",
    "    Level 4 (Difficulty: Hard):\n",
    "\n",
    "    \"\"\"\n",
    "    formatting =  {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"{init},{format}\"\n",
    "        }\n",
    "\n",
    "    level_meaning = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": level_meaning\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    return formatting, level_meaning"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:17:45.270569500Z",
     "start_time": "2024-01-11T20:17:45.244504700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# ask question to student\n",
    "def ask_question(student, sub_topic, user_type):\n",
    "    # make sure to only receive math answers and initialize the questions GPT will give\n",
    "    filter_subject = filter_answers()\n",
    "    filter_question = init_question(student, sub_topic,user_type)\n",
    "    formatting, level_meaning = question_formatting()\n",
    "    messages = [filter_subject, filter_question, formatting, level_meaning]\n",
    "    # print(messages)\n",
    "    # send the formatting to GPT and get a response\n",
    "    tutor_question = get_response_text_w_temp(messages,question_temp)\n",
    "    # here we print out the question GPT gives the student\n",
    "    print(f\"{tutor_question}: \\n\\n\")\n",
    "    # make sure the question is always in lower case\n",
    "    tutor_question = tutor_question.lower()\n",
    "    return tutor_question"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:17:45.634899600Z",
     "start_time": "2024-01-11T20:17:45.595289300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:17:46.254695Z",
     "start_time": "2024-01-11T20:17:46.247122300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello User/Student! \n",
      "picking the level manually will only affect the type of questions you get\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'level'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mask_question\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAlice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m2 digit division\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[8], line 5\u001B[0m, in \u001B[0;36mask_question\u001B[1;34m(student, sub_topic, user_type)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mask_question\u001B[39m(student, sub_topic, user_type):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;66;03m# make sure to only receive math answers and initialize the questions GPT will give\u001B[39;00m\n\u001B[0;32m      4\u001B[0m     filter_subject \u001B[38;5;241m=\u001B[39m filter_answers()\n\u001B[1;32m----> 5\u001B[0m     filter_question \u001B[38;5;241m=\u001B[39m \u001B[43minit_question\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msub_topic\u001B[49m\u001B[43m,\u001B[49m\u001B[43muser_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     formatting, level_meaning \u001B[38;5;241m=\u001B[39m question_formatting()\n\u001B[0;32m      7\u001B[0m     messages \u001B[38;5;241m=\u001B[39m [filter_subject, filter_question, formatting, level_meaning]\n",
      "Cell \u001B[1;32mIn[7], line 33\u001B[0m, in \u001B[0;36minit_question\u001B[1;34m(student, subtopic, user_type)\u001B[0m\n\u001B[0;32m     31\u001B[0m                 valid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     32\u001B[0m                 \u001B[38;5;66;03m# Reset student's level if needed\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m                 subtopic\u001B[38;5;241m.\u001B[39mlevel \u001B[38;5;241m=\u001B[39m custom_level\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# criteria: tell GPT scales for proficiency and level\u001B[39;00m\n\u001B[0;32m     36\u001B[0m init \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBased on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstudent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms database, the student\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms skill level for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msubtopic\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msubtopic\u001B[38;5;241m.\u001B[39mlevel\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Please give \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstudent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m a test question based on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msubtopic\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and follow up with a sentence like \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExplain how you got your answer\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Adjust the difficulty of the question based on his skill level and proficiency score. DO NOT include any other words. Do not put the answer in the prompt.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute 'level'"
     ]
    }
   ],
   "source": [
    "ask_question(\"Alice\", \"2 digit division\",\"user\") #test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:01.211259500Z",
     "start_time": "2024-01-11T20:17:57.948419900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:10.434688700Z",
     "start_time": "2024-01-11T20:18:10.428660800Z"
    }
   },
   "outputs": [],
   "source": [
    "# time: time it took the student to answer the question given from GPT\n",
    "# returns\n",
    "#   - the response the student gives\n",
    "#   - the time it takes to get a response form the student\n",
    "def get_student_timed_response():\n",
    "    start_time = time.time()\n",
    "\n",
    "    student_res = input() # response to question\n",
    "\n",
    "    end_time =  time.time()\n",
    "    end_time = end_time - start_time\n",
    "\n",
    "    return student_res, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\n",
    "def respond_to_student_ans(question, student_answer, student_name,gpt_ans_explanation,get_all_student_related_mistakes):\n",
    "    # take in the student_name's answer, and the topic\n",
    "    print(\"Answer: \\n\")\n",
    "    question_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are a math tutor. The question that the user is answering is '{question}'.\"\n",
    "\n",
    "    }\n",
    "    answer_explained = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"The GPT answer that you have found is derived below: \\n{gpt_ans_explanation}\\n\\n{student_name}'s answer is {student_answer}. Tell whether the student got the question correct based on the GPT answer and give and provide an explanation of the correct answer. Also explain where the student is incorrect\"\n",
    "    }\n",
    "\n",
    "    use_student_mistakes = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\" These are the mistakes that {student_name} made while doing these types of problems: {get_all_student_related_mistakes}. in your answer. high light how he has improved on his mistakes,and/or how he is still doing the same mistake. If the studnet does not currently have any related mistakes, dont mention anything about related mistakes\"\n",
    "    }\n",
    "    init_response_messages = [question_message,answer_explained,use_student_mistakes]\n",
    "\n",
    "    answer_res = get_response_text(init_response_messages)\n",
    "\n",
    "    print(f\"{answer_res}\\n\\n\")\n",
    "\n",
    "    return answer_res\n",
    "\n",
    "def grade_student_response(question, student_answer, student_name,solve_time, sub_topic,answer_res):\n",
    "\n",
    "    print(\"Evaluation: \\n\")\n",
    "    # if the question being asked is simple we want to make sure the user does not have to give an explanation if non is needed\n",
    "    # here are examples of questions that don't need  much explanation\n",
    "    simple_question_examples = \"\"\"\n",
    "    Addition: 2 + 3, 99 + 92\n",
    "    Subtraction: 10 - 4, 345 - 234\n",
    "    Multiplication: 5 * 6, 99 * 99\n",
    "    Division: 20 ÷ 4\n",
    "    Square of a number: 4**2, 78**2\n",
    "    Cube of a number: 3**3\n",
    "    \"\"\"\n",
    "    evaluation_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"The topic of the question is {sub_topic}. This is the question given to {student_name}: {question}. {student_name}'s answer is {student_answer}. This  is the answer you gave: {answer_res}.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"This I need you to evaluate {student_name}'s performance in terms of the following skill metrics: communication, interpretation, computation, conceptual, and the time taken to solve the question (it took the student {solve_time} seconds to complete the question. For each of these metrics, rate the skill out of 5, where 5 out of 5 is the best score, and 1 out of 5 is the worst score. make sure to have your evaluation in outline format. Also give an explanation on how {student_name} did not get the highest marks. Make sure to use Integers, NOT decimals \"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"if the question being asked is brief and does not require much of an explanation, automatically give the student a 5 out of 5 score for communication. The following are examples of questions that dont require the student to give a long explanation: {simple_question_examples}. for all questions similar to this, the metric score for communication will always be 5.\"\n",
    "\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \" if you cannot find any related mistakes for a metric, automatically give a score of 5 for the corresponding metric\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"at the end, give an average score based on the above metrics\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"make sure that you always have a time metric\"\n",
    "        }\n",
    "    ]\n",
    "    evaluation_res = get_response_text(evaluation_messages)\n",
    "    print(evaluation_res)\n",
    "    print(\" \\n\\n\")\n",
    "    metrics_scores = extract_metrics_scores(evaluation_res)\n",
    "\n",
    "    # print(metrics_scores)\n",
    "    return  metrics_scores\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:10.623281100Z",
     "start_time": "2024-01-11T20:18:10.582418500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# give students the ability to ask for clarification regarding a question they have about the answer to the question\n",
    "def get_gpt_clarification (question, gpt_answer, student_answer, previous_explanations):\n",
    "    # ask the student if they need clarification on a question.\n",
    "    # if they do. give them a chance to ask the question\n",
    "    # if they dont, then dont provide anything\n",
    "\n",
    "\n",
    "    # make sure the response safe and only related to mathematics\n",
    "    only_answer_math = f'''I am a math teacher for Grade K-12 in the United States. I am using the GPT API to help me answer my students' math questions. Please only answer my questions about math, and do not respond to any questions that are not about math.'''\n",
    "\n",
    "    only_answer_math_msg = create_message_part(only_answer_math,1)\n",
    "\n",
    "    previous_info = f\"\"\"\n",
    "    Question: {question},\n",
    "    GPT's answer ( assume this is correct): {gpt_answer},\n",
    "    student's answer (this could, or could not be correct){student_answer},\n",
    "    previous explanations to students questions:{previous_explanations}\n",
    "    \"\"\"\n",
    "    # create system message\n",
    "    previous_info_msg = create_message_part(previous_info,1)\n",
    "\n",
    "\n",
    "    # create message for the student's question on the math problem\n",
    "    student_question = input(\"Write down what you want clarification on\")\n",
    "    student_question_msg = create_message_part(student_question,3)\n",
    "\n",
    "    msgs = [only_answer_math_msg,previous_info_msg,student_question_msg]\n",
    "\n",
    "    GPT_res = get_response_text(msgs)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(GPT_res)\n",
    "\n",
    "    return GPT_res\n",
    "\n",
    "# GPT gives a detailed explanation given a student's question on the math problem\n",
    "# ques_explain: math question and the previous student questions asked and the GPT resposes given\n",
    "def student_clarification(question, gpt_answer, student_answer, previous_explanations):\n",
    "    # Ask the student if they want clarification about the answers given\n",
    "    need_clarification = input(\"If you want clarification, type 'Yes'. Type anything else to got to the evaluation section\\n\")\n",
    "\n",
    "    need_clarification = need_clarification.lower()\n",
    "    if need_clarification == \"yes\".lower():\n",
    "        # Get clarification from the student using the get_gpt_clarification function\n",
    "        new_clarification = get_gpt_clarification(question, gpt_answer, student_answer, previous_explanations)\n",
    "\n",
    "        # Update previous explanations with the new clarification\n",
    "        previous_explanations = previous_explanations + \"  ,  \" + new_clarification\n",
    "\n",
    "        # Recursive call to continue the clarification process\n",
    "        student_clarification(question, gpt_answer, student_answer, previous_explanations)\n",
    "    else:\n",
    "        print(\"Student questioning section has been completed.\\nNext: Metric scores for performance\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:10.790771700Z",
     "start_time": "2024-01-11T20:18:10.756397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# question = \"Solve for x: 2x + 5 = 15\"\n",
    "# gpt_answer = \"x = 5\"\n",
    "# student_answer = \"x = 6\"\n",
    "# previous_explanations = \"\"\n",
    "# student_clarification(question, gpt_answer, student_answer, previous_explanations)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:10.898259100Z",
     "start_time": "2024-01-11T20:18:10.863534600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "# gpt_res: evaluation on how the student answered the questions\n",
    "def extract_metrics_scores(gpt_res):\n",
    "    instruction = f'''\n",
    "\n",
    "\n",
    "    Here is the Evaluation for a certain studnet. \\n\\n{gpt_res}\\n\\n---\\n.\n",
    "\n",
    "    From this evaluation, extract it's evaluation metric numbers and put them in teh shape of a JSON file. Answer this question in the form of a JSON file\n",
    "\n",
    "\n",
    "'''\n",
    "    # get examples of what should be done.\n",
    "    example_1_eval = \"\"\"\n",
    "        Evaluation of Allan's Performance:\n",
    "\n",
    "        1. Communication: 4/5\n",
    "           - Allan effectively communicated his answer and explanation in a clear and concise manner. However, there could have been more elaboration and clarity in his explanation.\n",
    "\n",
    "        2. Interpretation: 5/5\n",
    "           - Allan correctly interpreted the given equation and understood the objective of isolating x.\n",
    "\n",
    "        3. Computation: 5/5\n",
    "           - Allan correctly performed the necessary computation steps to solve the equation and obtained the correct answer.\n",
    "\n",
    "        4. Conceptual Understanding: 4/5\n",
    "           - Allan demonstrated a good understanding of the concept of isolating x in an equation. However, his explanation could have included more conceptual details to further enhance his understanding.\n",
    "\n",
    "        5. Time Taken: 5/5\n",
    "           - Allan was able to solve the question in a relatively short amount of time, taking only 20 seconds.\n",
    "\n",
    "        Average Score: (4 + 5 + 5 + 4 + 5) / 5 = 4.6/5\n",
    "\n",
    "        Explanation:\n",
    "        Allan's performance was generally strong across all skill metrics. He effectively communicated his answer and demonstrated a good understanding of the concept. However, his explanation could have been more detailed and comprehensive, which affected his score in the communication and conceptual understanding categories. Overall, Allan performed well and achieved a high average score of 4.6 out of 5.\n",
    "        \"\"\"\n",
    "    # What the function should output\n",
    "    # TODO: if you are having issues with example_1_res, use the OLD version here\n",
    "    example_1_res_OLD = \"\"\"\n",
    "        {\n",
    "                {\n",
    "        \"overall_avg\": 4.6,\n",
    "        \"communication\": {\n",
    "            \"avg_score\": 4,\n",
    "            \"related_mistakes\": [\"could have been more elaboration and clarity in his explanation.\"]\n",
    "        },\n",
    "        \"interpretation\": {\n",
    "            \"avg_score\": 5,\n",
    "            \"related_mistakes\": []\n",
    "        },\n",
    "        \"computation\": {\n",
    "            \"avg_score\": 5,\n",
    "            \"related_mistakes\": []\n",
    "        },\n",
    "        \"conceptual\": {\n",
    "            \"avg_score\": 4,\n",
    "            \"related_mistakes\": [\"explanation could have included more conceptual details to further enhance his understanding\"]\n",
    "        },\n",
    "        \"time\": {\n",
    "            \"avg_score\": 5,\n",
    "            \"seconds\": 20\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "    \"\"\"\n",
    "    # What the function should output\n",
    "    example_1_res = '''\n",
    "                {\n",
    "        \"overall_avg\": 4.6,\n",
    "        \"communication\": {\n",
    "            \"score\": 4,\n",
    "            \"related_mistakes\": [\"could have been more elaboration and clarity in his explanation.\"]\n",
    "        },\n",
    "        \"interpretation\": {\n",
    "            \"score: 5,\n",
    "            \"related_mistakes\": []\n",
    "        },\n",
    "        \"computation\": {\n",
    "            \"score: 5,\n",
    "            \"related_mistakes\": []\n",
    "        },\n",
    "        \"conceptual\": {\n",
    "            \"score: 4,\n",
    "            \"related_mistakes\": [\"explanation could have included more conceptual details to further enhance his understanding\"]\n",
    "        },\n",
    "        \"time\": {\n",
    "            \"score: 5,\n",
    "            \"seconds\": 20\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "\n",
    "    example_2_eval = \"\"\"\n",
    "        Evaluation of Alice's Performance:\n",
    "\n",
    "    1. Communication: 2/5\n",
    "       - Alice's answer does not clearly explain the steps taken to subtract the numbers.\n",
    "       - The answer provided is incorrect and does not demonstrate a clear understanding of the subtraction process.\n",
    "\n",
    "    2. Interpretation: 1/5\n",
    "       - Alice misinterpreted the question and did not understand that regrouping (borrowing) was not allowed.\n",
    "       - The answer provided does not align with the given instructions.\n",
    "\n",
    "    3. Computation: 1/5\n",
    "       - Alice's answer of 24 is incorrect and does not reflect the correct subtraction calculation.\n",
    "       - The computation process used by Alice is flawed and does not follow the correct method of subtraction without regrouping.\n",
    "\n",
    "    4. Conceptual: 1/5\n",
    "       - Alice lacks a clear understanding of the concept of subtraction without regrouping.\n",
    "       - The incorrect answer and flawed computation process indicate a lack of conceptual understanding.\n",
    "\n",
    "    5. Time taken: 5/5\n",
    "       - Alice completed the question in a reasonable amount of time, indicating a decent level of speed and efficiency.\n",
    "\n",
    "    Average Score: (2 + 1 + 1 + 1 + 5) / 5 = 2/5\n",
    "\n",
    "    Explanation:\n",
    "    Alice's performance in this question is below average. She struggled with communication, interpretation, computation, and conceptual understanding. Her answer was incorrect, and she did not follow the correct method of subtraction without regrouping. Alice needs further practice and clarification on the concept of subtraction to improve her skills in this area.\n",
    "    \"\"\"\n",
    "    example_2_res = \"\"\"\n",
    "        {\n",
    "            \"overall_avg\": 2,\n",
    "            \"communication\": {\n",
    "                \"avg_score\": 2,\n",
    "                \"related_mistakes\": [\" does not clearly explain the steps taken to subtract the numbers.\"]\n",
    "            },\n",
    "            \"interpretation\": {\n",
    "                \"avg_score\": 1,\n",
    "                \"related_mistakes\": [misinterpreted the question and did not understand that regrouping (borrowing) was not allowed,The answer provided does not align with the given instructions.]\n",
    "            },\n",
    "            \"computation\": {\n",
    "                \"avg_score\": 1,\n",
    "                \"related_mistakes\": [does not follow the correct method of subtraction without regrouping.]\n",
    "            },\n",
    "            \"conceptual\": {\n",
    "                \"avg_score\": 1,\n",
    "                \"related_mistakes\": [\"lacks a clear understanding of the concept of subtraction without regrouping\"]\n",
    "            },\n",
    "            \"time\": {\n",
    "                \"avg_score\": 5,\n",
    "                \"seconds\": 20\n",
    "            }\n",
    "    }\n",
    "    \"\"\"\n",
    "    instruction_msg = create_message_part(instruction,1)\n",
    "    example_1_res_msg =  create_message_part(example_1_eval,3)\n",
    "    example_1_res_ans =  create_message_part(example_1_res,2)\n",
    "    example_2_res_msg =  create_message_part(example_2_eval,3)\n",
    "    example_2_res_ans =  create_message_part(example_2_res,2)\n",
    "\n",
    "    # add instructions and examples to messages\n",
    "    messages = [instruction_msg, example_1_res_msg, example_1_res_ans,example_2_res_msg,example_2_res_ans]\n",
    "\n",
    "    # get JSON data in form of response string\n",
    "    metric_scores_string =  get_response_text(messages)\n",
    "\n",
    "    # make the string a JSON\n",
    "\n",
    "    metric_scores_json = eval(metric_scores_string)\n",
    "    return metric_scores_json\n",
    "\n",
    "    # # print(metric_scores_json)\n",
    "    # return metric_scores_string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:10.992614900Z",
     "start_time": "2024-01-11T20:18:10.972994400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# question: String\n",
    "# student, sub_topic: custom Objects\n",
    "# all_student_subtopic_mistakes: dictionary\n",
    "# receive student's answer, respond to their answer, and update their statistics\n",
    "def receive_respond_and_update(question, student, sub_topic, all_student_subtopic_mistakes):\n",
    "    # Get the student's response and the time taken\n",
    "    student_answer, solve_time = get_student_timed_response()\n",
    "\n",
    "    # Grade the student's response using the given question, student response, time, and sub_topic\n",
    "\n",
    "    # get the answer + explanation that GPT provides with python doing the math.\n",
    "    # uses \"memPrompt\" like memory\n",
    "    gpt_ans_explanation, _ = get_answer_explanation_with_memory(question)\n",
    "\n",
    "    answer_res = respond_to_student_ans(question, student_answer, student.name, gpt_ans_explanation,all_student_subtopic_mistakes)\n",
    "\n",
    "    previous_explanations = \" \" # we start the previous explanations empty\n",
    "    student_clarification(question,answer_res,student_answer,previous_explanations)\n",
    "    gpt_res = grade_student_response(question, student_answer, student.name, solve_time, sub_topic.name,answer_res)\n",
    "\n",
    "    # Extract metric updates from the GPT response\n",
    "    metric_updates = extract_metrics_scores(gpt_res)\n",
    "\n",
    "    # Return the metric updates\n",
    "    return metric_updates"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:11.128931Z",
     "start_time": "2024-01-11T20:18:11.111398900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:11.281981Z",
     "start_time": "2024-01-11T20:18:11.262633300Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO make a test portion\n",
    "#TODO Evaluating AI/Student's Answer to question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# converts question's format into python formatting\n",
    "def question_python_notation(question):\n",
    "    system_text = \"\"\"\n",
    "    make the following questions in python notation:\n",
    "\n",
    "    Here is an example\"\n",
    "\n",
    "    User: \"What is 0.9^6\" in python notation\n",
    "\n",
    "    Assistant: \"What is 0.9**6\"\n",
    "\n",
    "    User: \"What is 0.9 raised to the power of 6\" in python notation\n",
    "\n",
    "    Assistant: \"What is 0.9**6\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    prompt_text = question\n",
    "    system_msg = create_message_part(system_text,1)\n",
    "    prompt_msg = create_message_part(prompt_text,3)\n",
    "    messages = [system_msg,prompt_msg]\n",
    "    converted_notation = get_response_text(messages)\n",
    "    # print( converted_notation)\n",
    "    return  converted_notation\n",
    "\n",
    "# using question given and answer given in python, make GPT backtrack to find a solution that gets the answer\n",
    "def backtrack_to_explanation(question, answer):\n",
    "    # to make sure that are answers are accurate and consistant, we make sure that GPT receives the answers in python notation\n",
    "    converted_question = question_python_notation(question)\n",
    "\n",
    "    system_text = \"You will be given a question, and an answer to a question. It is your job to explain the correct way how to get from the question to the answer step by step.  \"\n",
    "    prompt_text = f\"the question is {converted_question}, the answer is {answer}\"\n",
    "\n",
    "    system_msg = create_message_part(system_text,1)\n",
    "    prompt_msg = create_message_part(prompt_text,3)\n",
    "\n",
    "    messages = [system_msg,prompt_msg]\n",
    "    explanation = get_response_text(messages)\n",
    "    print(explanation)\n",
    "    return explanation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:11.401667600Z",
     "start_time": "2024-01-11T20:18:11.394620900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "#### TRYING TO run python code to get question right\n",
    "def question_to_code_block(question):\n",
    "    message = [\n",
    "        {\n",
    "            # the code needed for \"exec\" to work need specific formatting\n",
    "            # make sure GPT will only give answers that are executable in python\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            When asked anything, the answer will always be in python code, using a function. no other comments. make sure to call the function\n",
    "\n",
    "            Example\n",
    "\n",
    "            user: what is 0.9**6\n",
    "\n",
    "            assistant:\n",
    "\n",
    "            def test()\n",
    "                value = 0.9**6\n",
    "                ans = f\"the answer to the question is {value}\"\n",
    "                return ans\n",
    "            result = test() # MAKE SURE TO INCLUDE THE 'result = <function()>'\n",
    "            \"\"\"\n",
    "            # \"When asked anything, the answer will always be in python code, using a function. no other comments. use a print statement when calling the function\"\n",
    "            # \"When asked anything, the answer will always be in python code, using a function. no other comments, You are allowed to use external libraries such as numpy, scipy, etc\"\n",
    "\n",
    "            # \"When asked anything, the answer will always be in python code. no other comments, just python code. make sure the return is in a print statement\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": question\n",
    "        }\n",
    "\n",
    "    ]\n",
    "    code_block = get_response_text(message)\n",
    "    return code_block\n",
    "# This function takes a code block as input and returns the value given when the python code is executed\n",
    "\n",
    "#TODO the use of \"exec could possible be a security risk\n",
    "def code_block_to_variable(code_block):\n",
    "    # Create an empty dictionary to store the variables that are created in the executed code.\n",
    "    data = {}\n",
    "\n",
    "    # Execute the code block and store the results in the dictionary `data`.\n",
    "    exec(code_block, None, data)\n",
    "\n",
    "    # Get the value of the variable `result` from the dictionary `data`.\n",
    "    var = data[\"result\"]\n",
    "\n",
    "    return var\n",
    "\n",
    "def solve_simple_math(question):\n",
    "    code_block = question_to_code_block(question)\n",
    "    print(f\"python code: {code_block}\")\n",
    "    ans = code_block_to_variable(code_block)\n",
    "    # convert answer into string\n",
    "    print(f\"answer: {ans}\")\n",
    "    return ans\n",
    "\n",
    "def explain_simple_math(question):\n",
    "    ans = solve_simple_math(question)\n",
    "    # print(f\" this is {str(ans)}\")\n",
    "    explanation = backtrack_to_explanation(question,ans)\n",
    "    # return explanation\n",
    "    return ans\n",
    "\n",
    "#TODO Self Refine\n",
    "def self_refine_answer(question, answer): # based on \"Self Refine\" paper\n",
    "    # set up th question and answer so that GPT the reflect on it's own code\n",
    "    set_up_question = f\"Here is the following question: {question}\\n\"\n",
    "    set_up_answer = f'''\n",
    "\n",
    "    Here is the python code that lead to an answer I was previously {answer}\n",
    "\n",
    "    '''\n",
    "    instructions = '''If one exists, identify the error in the code and refine the solution through an iterative process of introspection and feedback'''\n",
    "\n",
    "    question_msg = create_message_part(set_up_question,1)\n",
    "    answer_msg = create_message_part(set_up_answer,1)\n",
    "    instruction_msg = create_message_part(set_up_question,3)\n",
    "\n",
    "    messages = [question_msg,answer_msg,instruction_msg]\n",
    "\n",
    "    res = get_response_text(messages)\n",
    "\n",
    "    pass\n",
    "#TODO update memPropmt and studnet_learning to include Self_Refine\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:11.551727300Z",
     "start_time": "2024-01-11T20:18:11.529644900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "q1 = \"What is 0.96**5\"\n",
    "q2 = \"If x + y = 0, and y + 2 = 24, what are x and y\"\n",
    "q3 = \"What is the derivative of  ln(x) with respect to x\"\n",
    "q4 = '''\n",
    "Twenty dozen cups cost $1200 less than the total cost of\n",
    "half a dozen plates sold at $6000 each.\n",
    "Calculate the total cost of buying each cup.\n",
    "''' # Example from Self Reliant Paper\n",
    "\n",
    "# code_b = question_to_code_block()\n",
    "# code_b\n",
    "#\n",
    "# ans1 = solve_simple_math(code_b)\n",
    "\n",
    "# explain_simple_math(q1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:11.691664300Z",
     "start_time": "2024-01-11T20:18:11.675111800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# 0.96**5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:12.033243900Z",
     "start_time": "2024-01-11T20:18:12.015560600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# query = \"Calculate the area of a rectangle with length 5 and width 8.\"\n",
    "# Memory.find_most_similar_memory(query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:12.318301400Z",
     "start_time": "2024-01-11T20:18:12.289327800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "\n",
    "# creates prompt with question and feedback if it exists\n",
    "def create_prompt(question, feedback):\n",
    "    # make the question and feedback into one prompt\n",
    "    question_msg = create_message_part(question,3)\n",
    "\n",
    "    set_up_msg = \"user feedback:\"\n",
    "    prepare_for_feedback = create_message_part(set_up_msg,3)\n",
    "\n",
    "    # feedback is given by the system\n",
    "    feedback_msg = create_message_part(feedback,1)\n",
    "\n",
    "    show_explanation = \"make sure to explain how you got to your answer\"\n",
    "    show_explanation_msg = create_message_part(show_explanation,1)\n",
    "\n",
    "    prompt = [question_msg, prepare_for_feedback, feedback_msg,show_explanation_msg]\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def get_answer_from_explanation(explained_ans):\n",
    "    instruction = \"From the given explanation, give only the question solved and the answer given\"\n",
    "\n",
    "    instruction_msg = create_message_part(instruction,1)\n",
    "\n",
    "    explained_ans_msg = create_message_part(explained_ans,3)\n",
    "\n",
    "    msgs = [instruction_msg,explained_ans_msg]\n",
    "\n",
    "    ans = get_response_text(msgs)\n",
    "\n",
    "    return ans\n",
    "\n",
    "# splits up explained answer into two parts: The answer itself and the explanation that leads to the answer\n",
    "def get_answer_and_explanation(prompt):\n",
    "\n",
    "    # generate the explained answer\n",
    "    explanation = get_response_text(prompt)\n",
    "    answer = get_answer_from_explanation(explanation)\n",
    "    return explanation, answer\n",
    "\n",
    "# give user feedback to perosn\n",
    "def send_feedback(question, feedback):\n",
    "    # get the Memory.json data\n",
    "    data = get_ext_data(memory_path)\n",
    "    # Search for the question in the database\n",
    "    found_question = False\n",
    "\n",
    "    for entry in data:\n",
    "        if entry[\"Question\"] == question:\n",
    "            # Add the feedback to the existing entry\n",
    "            print(entry[\"Feedback\"])\n",
    "            entry[\"Feedback\"].append(feedback)\n",
    "            found_question = True\n",
    "            print(\"feedback has been added to the question\")\n",
    "            break\n",
    "\n",
    "    # If the question is not in the database, add a new JSON entry\n",
    "    if not found_question:\n",
    "        new_entry = {\n",
    "            \"Question\": question,\n",
    "            \"Feedback\": [feedback],\n",
    "        }\n",
    "        data.append(new_entry)\n",
    "        print(\"the question and the feedback has been added to memory\")\n",
    "\n",
    "    # print(\"Memory database has been updated\")\n",
    "\n",
    "\n",
    "    # update the Memory.json file with the new information\n",
    "    post_ext_data(data,memory_path)\n",
    "\n",
    "# will update the memory if the user spots a mistake that GPT has made in the answer and/or the explanation of the answer\n",
    "def update_memory(question, answer, explanation):\n",
    "    # first display the answer to the user\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(f\"Explanation: {explanation}\\n\")\n",
    "    need_feedback = input(\"does the answer and explanation above require any feedback: 'Yes', or 'No'\")\n",
    "    if need_feedback == 'Yes':\n",
    "        feedback = input(\"What needs to be improved in the analysis process?\")\n",
    "        memories0 = Memory.Memories() # creates Memories Object\n",
    "        memories0.update_memory_feedback(question, feedback)\n",
    "    else:\n",
    "        print(\"Memory will not be updated\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:12.501262400Z",
     "start_time": "2024-01-11T20:18:12.462373300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# GPT answser the question with the feedback memory json\n",
    "def get_answer_explanation_with_memory(question):\n",
    "    # get the feedback associated with the most similar question\n",
    "    _,similar_feedback = Memory.find_most_similar_memory(question)\n",
    "    # convert the list to a string\n",
    "    feedback_str = f\"{similar_feedback}\"\n",
    "    # print(type(feedback_str))\n",
    "    print(f\"found feedback from memory.json: {feedback_str}\")\n",
    "    prompt = create_prompt(question,feedback_str)\n",
    "\n",
    "    # get the GPT generated answer and explanation\n",
    "    #ans_explanation: gives both the answer to the quesiton and the explanation of the answer\n",
    "    ans_explanation, answer = get_answer_and_explanation(prompt)\n",
    "    return ans_explanation,answer\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:12.759372700Z",
     "start_time": "2024-01-11T20:18:12.737329500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# based off \"MemPrompt: Memory-assisted Prompt Editing with User Feedback\" paper\n",
    "def mem_prompt_learning():\n",
    "    sub_topic_name = input(\"Enter the sub-topic you want to learn: \")\n",
    "    user_type = \"trainer\"\n",
    "    \n",
    "    # make subtopic and studnet objects we will use just for training\n",
    "    # nothing will chagne in teh students database collection on MongoDB\n",
    "    sub_topic_placeholder = students.Subtopic(sub_topic_name,1)\n",
    "    student_placeholder = students.Student(\"trainer\",1) # placeholder for a student's name. This will NOT negatively affect the ask_question function\n",
    "\n",
    "    # get the question\n",
    "    question = ask_question(student_placeholder,sub_topic_placeholder,user_type)\n",
    "    # find the question, or the most similar question that's in the database already\n",
    "    # get the GPT generated answer and explanation\n",
    "    explanation, answer = get_answer_explanation_with_memory(question)\n",
    "\n",
    "    # update the memory.json file ( if the answer is already correct, then nothing in the database will change)\n",
    "\n",
    "    update_memory(question, answer, explanation)\n",
    "\n",
    "    # Ask the student if they want to be asked another question.\n",
    "    answer = input(\"Do you want another question? 'yes' or 'no' \")\n",
    "    \n",
    "    answer = answer.lower()\n",
    "    while answer not in (\"yes\", \"no\"):\n",
    "        answer = input(\"Invalid input: Please enter 'yes' or 'no': \")\n",
    "\n",
    "    if answer == \"yes\":\n",
    "        mem_prompt_learning()\n",
    "    else:\n",
    "        print(\"Thank you training GPT Tutor! Have a great day.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:13.215461500Z",
     "start_time": "2024-01-11T20:18:13.168397200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "\n",
    "# asks student question, evaluates and updates their database\n",
    "def student_learning():\n",
    "\n",
    "    user_type = \"user\"\n",
    "    # get students database collection from MongoDB\n",
    "    main_collection = \"Section0\"\n",
    "    StudentCollection = students.StudentsCollection(main_collection)\n",
    "    all_student_names = StudentCollection.current_student_names()\n",
    "\n",
    "\n",
    "    \"\"\"Asks the student a question and updates their stats.\"\"\"\n",
    "    full_name = input(\"Enter your full name (Example: John Doe): \")\n",
    "    grade_level = input(\"What grade are you in (Grade 1-12): \")\n",
    "    sub_topic_name = input(\"Enter the sub-topic you want to learn: \")\n",
    "\n",
    "    # if student is in database, get the object\n",
    "    if full_name in all_student_names:\n",
    "        print(f\"{full_name} is already in the database\")\n",
    "        student = StudentCollection.get_student(full_name)\n",
    "    else:\n",
    "        # if the student is not in the database, create the object\n",
    "        print(f\"{full_name} will be added to the database\")\n",
    "        student = students.Student(full_name,float(grade_level)) # initialize student\n",
    "\n",
    "\n",
    "    mistakes = [] # initialize mistakes array for student\n",
    "    # find out if the has data related to the subtopic\n",
    "    if sub_topic_name in student.current_subtopic_names():\n",
    "        sub_topic = student.get_subtopic(sub_topic_name)\n",
    "    else:\n",
    "        sub_topic = students.Subtopic(sub_topic_name,1)\n",
    "        # connect subtopic object  to student object\n",
    "        student.add_subtopic(sub_topic)\n",
    "        sub_topic = student.get_subtopic(sub_topic_name)\n",
    "\n",
    "        # find all student's old mistakes for subtopic\n",
    "        mistakes = sub_topic.metrics.get_all_mistakes()\n",
    "        # mistakes is a map with the following keys: communication, interpretation, computation, and conceptual\n",
    "\n",
    "    # ask the student a question\n",
    "    question = ask_question(student.name, sub_topic, user_type)\n",
    "\n",
    "    # print(question)\n",
    "\n",
    "    # receive answer,  calculate GPT answer, have a chance for the student to ask questions, evaluate student\n",
    "    metric_updates = receive_respond_and_update(question, student, sub_topic, mistakes)\n",
    "\n",
    "    # return metric_updates\n",
    "    # # update the database\n",
    "    # \n",
    "    sub_topic.update_subtopic(metric_updates)\n",
    "\n",
    "    # remove old object and add new object ( updates object if it already is in database)\n",
    "    if student.name in all_student_names:\n",
    "        StudentCollection.delete_student(student)\n",
    "\n",
    "    StudentCollection.add_student(student)\n",
    "    # \n",
    "    # StudentCollection\n",
    "\n",
    "    # Ask the student if they want to be asked another question.\n",
    "    answer = input(\"Do you want another question? 'yes' or 'no' \")\n",
    "    \n",
    "    answer = answer.lower() # make the 'Yes' or 'No' lowercase\n",
    "    \n",
    "    while answer not in (\"yes\", \"no\"):\n",
    "        answer = input(\"Invalid input; Please enter 'yes' or 'no': \")\n",
    "\n",
    "    if answer == \"yes\":\n",
    "        student_learning()\n",
    "    else:\n",
    "        print(\"Thank you for using GPT Tutor! Have a great day.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:13.787206100Z",
     "start_time": "2024-01-11T20:18:13.758331300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    The main function that starts the learning process for either....\n",
    "    The student, or GPT\n",
    "    \"\"\"\n",
    "    # User: Uses GPT_Tutor to learn math\n",
    "    # Trainer: Testing GPT_Tutors knowledge ( ~ to MemPrompt paper)\n",
    "    valid = False # valid if you enter either 'user' or 'trainer'\n",
    "    while not valid:\n",
    "        usage_type = input(\"Type 'user' if you use GPT to learn. \\nType 'trainer' if you want to train GPT_Tutor.\\nType 'exit' to exit the program\\n\")\n",
    "        usage_type = usage_type.lower() # makes sure letters are in lowercase\n",
    "        if usage_type == \"user\":\n",
    "            valid = True\n",
    "            # Start the learning process.\n",
    "            student_learning()\n",
    "        if usage_type == \"trainer\":\n",
    "            valid = True\n",
    "            # Start GPT learning process\n",
    "            mem_prompt_learning()\n",
    "        if usage_type == \"exit\":\n",
    "            valid = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:18:14.288066600Z",
     "start_time": "2024-01-11T20:18:14.282056300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe is already in the database\n",
      "Student found: John Doe\n",
      " Addition is already in John Doe's database\n",
      "Hello User/Student! \n",
      "picking the level manually will only affect the type of questions you get\n",
      "Level 3 (Difficulty: Moderate):\n",
      "\n",
      "Add the following numbers:\n",
      "\n",
      "27 + 14\n",
      "\n",
      "Explain how you got your answer.: \n",
      "\n",
      "level 3 (difficulty: moderate):\n",
      "\n",
      "add the following numbers:\n",
      "\n",
      "27 + 14\n",
      "\n",
      "explain how you got your answer.\n",
      "found feedback from memory.json: ['answer is correct, but your thought process takes too long']\n",
      "Answer: \n",
      "Based on the GPT answer, the student John Doe made the following mistakes:\n",
      "\n",
      "1. Incorrect addition: John Doe calculated 27 + 14 as 25, which is incorrect. The correct sum is 41.\n",
      "\n",
      "However, since the GPT answer does not mention any specific mistakes made by John Doe, it is not possible to determine if he has improved or is still making the same mistake.\n",
      "\n",
      "Student questioning section has been completed.\n",
      "Next: Metric scores for performance\n",
      "\n",
      "Evaluation: \n",
      "Evaluation of John Doe's Performance:\n",
      "\n",
      "Communication: 3 out of 5\n",
      "- John Doe provided an answer, but did not explain how he arrived at his answer. \n",
      "\n",
      "Interpretation: 5 out of 5\n",
      "- John Doe correctly understood the question and attempted to solve it.\n",
      "\n",
      "Computation: 1 out of 5\n",
      "- John Doe made an incorrect addition, calculating 27 + 14 as 25 instead of the correct answer of 41.\n",
      "\n",
      "Conceptual: 2 out of 5\n",
      "- John Doe did not demonstrate a clear understanding of addition and made a mistake in the calculation.\n",
      "\n",
      "Time: 5 out of 5\n",
      "- John Doe took 2.7175168991088867 seconds to complete the question, which is within a reasonable time frame.\n",
      "\n",
      "Average Score: (3 + 5 + 1 + 2 + 5) / 5 = 3.2 out of 5\n",
      "\n",
      "Explanation:\n",
      "John Doe's performance was below average due to the mistakes made in computation and conceptual understanding. He incorrectly added the numbers and did not demonstrate a clear understanding of addition. However, he correctly interpreted the question and provided an answer, albeit without an explanation. His time taken to solve the question was within a reasonable range. Overall, there is room for improvement in John Doe's addition skills.\n",
      " \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'related_mistakes'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Check if the script is being run directly\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m----> 3\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[29], line 15\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     13\u001B[0m     valid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m# Start the learning process.\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     \u001B[43mstudent_learning\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m usage_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrainer\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     17\u001B[0m     valid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[28], line 51\u001B[0m, in \u001B[0;36mstudent_learning\u001B[1;34m()\u001B[0m\n\u001B[0;32m     46\u001B[0m metric_updates \u001B[38;5;241m=\u001B[39m receive_respond_and_update(question, student, sub_topic, mistakes)\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# return metric_updates\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# # update the database\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# \u001B[39;00m\n\u001B[1;32m---> 51\u001B[0m \u001B[43msub_topic\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_subtopic\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetric_updates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;66;03m# remove old object and add new object ( updates object if it already is in database)\u001B[39;00m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m student\u001B[38;5;241m.\u001B[39mname \u001B[38;5;129;01min\u001B[39;00m all_student_names:\n",
      "File \u001B[1;32m~\\Programming Projects\\WPI Projects\\GPT_Toy_Tutor\\command_line_toy\\students.py:169\u001B[0m, in \u001B[0;36mSubtopic.update_subtopic\u001B[1;34m(self, all_updates)\u001B[0m\n\u001B[0;32m    167\u001B[0m level \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlevel\n\u001B[0;32m    168\u001B[0m \u001B[38;5;66;03m# update the metrics\u001B[39;00m\n\u001B[1;32m--> 169\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_updates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;66;03m# update the amount of quesitons\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;66;03m# add 1 to the index that corresponds to the level ( \"index -1\" because the array is 0 based)\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_questions_answered[level\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\Programming Projects\\WPI Projects\\GPT_Toy_Tutor\\command_line_toy\\students.py:219\u001B[0m, in \u001B[0;36mMetrics.update\u001B[1;34m(self, all_updates)\u001B[0m\n\u001B[0;32m    217\u001B[0m avg_comp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomputation\u001B[38;5;241m.\u001B[39mupdate(all_updates[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcomputation\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    218\u001B[0m avg_conc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconceptual\u001B[38;5;241m.\u001B[39mupdate(all_updates[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconceptual\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m--> 219\u001B[0m avg_time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_updates\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtime\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;66;03m# update overall_avg\u001B[39;00m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;66;03m# get average score of the newly calculated metrics\u001B[39;00m\n\u001B[0;32m    222\u001B[0m new_average \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean([avg_comm,avg_interp,avg_comp,avg_conc,avg_time])\n",
      "File \u001B[1;32m~\\Programming Projects\\WPI Projects\\GPT_Toy_Tutor\\command_line_toy\\students.py:278\u001B[0m, in \u001B[0;36mMetric.update\u001B[1;34m(self, update)\u001B[0m\n\u001B[0;32m    273\u001B[0m \u001B[38;5;66;03m# print(\"score avg\", self.avg_score)\u001B[39;00m\n\u001B[0;32m    274\u001B[0m \u001B[38;5;66;03m# print(\"previous scores\",self.previous_scores)\u001B[39;00m\n\u001B[0;32m    275\u001B[0m \n\u001B[0;32m    276\u001B[0m \u001B[38;5;66;03m# replace related mistakes\u001B[39;00m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelated_mistakes\u001B[39m\u001B[38;5;124m'\u001B[39m): \u001B[38;5;66;03m# if the section has a related_mistakes section, and section is NOT time\u001B[39;00m\n\u001B[1;32m--> 278\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelated_mistakes \u001B[38;5;241m=\u001B[39m \u001B[43mupdate\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrelated_mistakes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m    279\u001B[0m     \u001B[38;5;66;03m# print(\"related mistakes\",self.related_mistakes)\u001B[39;00m\n\u001B[0;32m    280\u001B[0m \n\u001B[0;32m    281\u001B[0m \u001B[38;5;66;03m# if there is  time attribute, update the time data:\u001B[39;00m\n\u001B[0;32m    282\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecent_times\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "\u001B[1;31mKeyError\u001B[0m: 'related_mistakes'"
     ]
    }
   ],
   "source": [
    "# Check if the script is being run directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-11T20:19:17.044395400Z",
     "start_time": "2024-01-11T20:18:22.074288400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# grade_student_response(\"What is 99 * 99\", \"99 * 99 = 9801\",\"Alice\",20, \"basic arithmetic\", \"the answer is 9801\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-26T03:27:33.948632400Z",
     "start_time": "2023-10-26T03:27:33.931591400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "outputs": [],
   "source": [
    "# student_learning()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T20:30:29.760250500Z",
     "start_time": "2023-08-13T20:30:29.743065300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
