{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:12:38.232675400Z",
     "start_time": "2023-07-13T14:12:38.210672500Z"
    },
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:12:38.395905300Z",
     "start_time": "2023-07-13T14:12:38.337031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grade</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Math Topic</th>\n",
       "      <th>Sub_topic_1</th>\n",
       "      <th>Sub_topic_2</th>\n",
       "      <th>Sub_topic_3</th>\n",
       "      <th>Sub_topic_4</th>\n",
       "      <th>Sub_topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>Counting numbers</td>\n",
       "      <td>Counting objects</td>\n",
       "      <td>Counting forward and backward</td>\n",
       "      <td>Skip counting by 2s and 5s</td>\n",
       "      <td>Counting in different patterns</td>\n",
       "      <td>Counting on a number line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>Comparing numbers</td>\n",
       "      <td>Comparing numbers using symbols</td>\n",
       "      <td>Comparing numbers using objects</td>\n",
       "      <td>Comparing numbers</td>\n",
       "      <td>Comparing quantities</td>\n",
       "      <td>Comparing values</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>Addition within 20</td>\n",
       "      <td>Addition without regrouping</td>\n",
       "      <td>Addition with regrouping</td>\n",
       "      <td>Word problems with addition</td>\n",
       "      <td>Adding three numbers</td>\n",
       "      <td>Solving addition equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>Subtraction within 20</td>\n",
       "      <td>Subtraction without regrouping</td>\n",
       "      <td>Subtraction with regrouping</td>\n",
       "      <td>Word problems with subtraction</td>\n",
       "      <td>Subtracting from a given number</td>\n",
       "      <td>Solving subtraction equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>Place value within 100</td>\n",
       "      <td>Place value of tens and ones</td>\n",
       "      <td>Expanded form of two-digit numbers</td>\n",
       "      <td>Comparing two-digit numbers</td>\n",
       "      <td>Skip counting in tens and ones</td>\n",
       "      <td>Representing numbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>12</td>\n",
       "      <td>High School</td>\n",
       "      <td>Trigonometric identities and equations</td>\n",
       "      <td>Proving trigonometric identities</td>\n",
       "      <td>Solving trigonometric equations and inequalities</td>\n",
       "      <td>Complex numbers and their applications</td>\n",
       "      <td>Modeling with trigonometric functions</td>\n",
       "      <td>Differential equations and series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>12</td>\n",
       "      <td>High School</td>\n",
       "      <td>Analytic geometry and vectors</td>\n",
       "      <td>Lines, planes, and their equations</td>\n",
       "      <td>Vector operations and properties</td>\n",
       "      <td>Applications of vectors in geometry and physics</td>\n",
       "      <td>Three-dimensional geometry and vectors</td>\n",
       "      <td>Dot product, cross product, and their applicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>12</td>\n",
       "      <td>High School</td>\n",
       "      <td>Probability and statistics</td>\n",
       "      <td>Probability rules and calculations</td>\n",
       "      <td>Discrete and continuous random variables</td>\n",
       "      <td>Statistical data analysis and inference</td>\n",
       "      <td>Hypothesis testing and confidence intervals</td>\n",
       "      <td>Regression analysis and correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>12</td>\n",
       "      <td>High School</td>\n",
       "      <td>Calculus</td>\n",
       "      <td>Limits and continuity</td>\n",
       "      <td>Derivatives and their applications</td>\n",
       "      <td>Integrals and their applications</td>\n",
       "      <td>Differential equations and modeling</td>\n",
       "      <td>Multivariable calculus and vector calculus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>12</td>\n",
       "      <td>High School</td>\n",
       "      <td>Discrete mathematics and financial mathematics</td>\n",
       "      <td>Combinatorics and counting principles</td>\n",
       "      <td>Graph theory and networks</td>\n",
       "      <td>Financial mathematics and investments</td>\n",
       "      <td>Optimization and linear programming</td>\n",
       "      <td>Cryptography and coding theory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Grade Education Level                                      Math Topic   \n",
       "0        1      Elementary                                Counting numbers  \\\n",
       "1        1      Elementary                               Comparing numbers   \n",
       "2        1      Elementary                              Addition within 20   \n",
       "3        1      Elementary                           Subtraction within 20   \n",
       "4        1      Elementary                          Place value within 100   \n",
       "..     ...             ...                                             ...   \n",
       "121     12     High School          Trigonometric identities and equations   \n",
       "122     12     High School                   Analytic geometry and vectors   \n",
       "123     12     High School                      Probability and statistics   \n",
       "124     12     High School                                        Calculus   \n",
       "125     12     High School  Discrete mathematics and financial mathematics   \n",
       "\n",
       "                               Sub_topic_1   \n",
       "0                         Counting objects  \\\n",
       "1          Comparing numbers using symbols   \n",
       "2              Addition without regrouping   \n",
       "3           Subtraction without regrouping   \n",
       "4             Place value of tens and ones   \n",
       "..                                     ...   \n",
       "121       Proving trigonometric identities   \n",
       "122     Lines, planes, and their equations   \n",
       "123     Probability rules and calculations   \n",
       "124                  Limits and continuity   \n",
       "125  Combinatorics and counting principles   \n",
       "\n",
       "                                          Sub_topic_2   \n",
       "0                       Counting forward and backward  \\\n",
       "1                     Comparing numbers using objects   \n",
       "2                            Addition with regrouping   \n",
       "3                         Subtraction with regrouping   \n",
       "4                  Expanded form of two-digit numbers   \n",
       "..                                                ...   \n",
       "121  Solving trigonometric equations and inequalities   \n",
       "122                  Vector operations and properties   \n",
       "123          Discrete and continuous random variables   \n",
       "124                Derivatives and their applications   \n",
       "125                         Graph theory and networks   \n",
       "\n",
       "                                         Sub_topic_3   \n",
       "0                         Skip counting by 2s and 5s  \\\n",
       "1                                  Comparing numbers   \n",
       "2                        Word problems with addition   \n",
       "3                     Word problems with subtraction   \n",
       "4                        Comparing two-digit numbers   \n",
       "..                                               ...   \n",
       "121           Complex numbers and their applications   \n",
       "122  Applications of vectors in geometry and physics   \n",
       "123          Statistical data analysis and inference   \n",
       "124                 Integrals and their applications   \n",
       "125            Financial mathematics and investments   \n",
       "\n",
       "                                     Sub_topic_4   \n",
       "0                 Counting in different patterns  \\\n",
       "1                           Comparing quantities   \n",
       "2                           Adding three numbers   \n",
       "3                Subtracting from a given number   \n",
       "4                 Skip counting in tens and ones   \n",
       "..                                           ...   \n",
       "121        Modeling with trigonometric functions   \n",
       "122       Three-dimensional geometry and vectors   \n",
       "123  Hypothesis testing and confidence intervals   \n",
       "124          Differential equations and modeling   \n",
       "125          Optimization and linear programming   \n",
       "\n",
       "                                           Sub_topic_5  \n",
       "0                            Counting on a number line  \n",
       "1                                     Comparing values  \n",
       "2                           Solving addition equations  \n",
       "3                        Solving subtraction equations  \n",
       "4                                 Representing numbers  \n",
       "..                                                 ...  \n",
       "121                  Differential equations and series  \n",
       "122  Dot product, cross product, and their applicat...  \n",
       "123                Regression analysis and correlation  \n",
       "124         Multivariable calculus and vector calculus  \n",
       "125                     Cryptography and coding theory  \n",
       "\n",
       "[126 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get syllabus\n",
    "df1 = pd.read_csv('topics.csv')\n",
    "df2 = pd.read_excel('GPT_tutor_topics(sub_topics_included).xlsx')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T13:47:30.999394400Z",
     "start_time": "2023-07-13T13:47:30.890000100Z"
    }
   },
   "outputs": [],
   "source": [
    "# get key and model\n",
    "openai.api_key = \"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\"\n",
    "model_35 = \"gpt-3.5-turbo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T13:47:32.291551900Z",
     "start_time": "2023-07-13T13:47:32.258998500Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "# API responses\n",
    "def get_response(messages):\n",
    "    res = openai.ChatCompletion.create(\n",
    "        model = model_35,\n",
    "        messages = messages,\n",
    "        temperature = 0 # make sure responses are deterministic/consistent\n",
    "    )\n",
    "    return res\n",
    "def get_response_text(messages):\n",
    "    res = get_response(messages)\n",
    "    return res['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T13:47:33.153726600Z",
     "start_time": "2023-07-13T13:47:33.128169700Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_student_in_database():\n",
    "    while True:\n",
    "        student_in_database = input(\"press '1' if you are in the database, press '2' if you are not: \")\n",
    "\n",
    "        if student_in_database == '1':\n",
    "            student_in_database = True\n",
    "        elif student_in_database == '2':\n",
    "            student_in_database = False\n",
    "        else:\n",
    "            print(\"Invalid input. Please choose '1' or '2'.\")\n",
    "        break\n",
    "\n",
    "    return student_in_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T18:04:50.761329800Z",
     "start_time": "2023-07-13T18:04:50.737034100Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def student_sub_topic_stats(student, sub_topic):\n",
    "    # Read the JSON file\n",
    "    file_path = 'students.json'\n",
    "    with open(file_path, \"r\") as file:\n",
    "        database = json.load(file)\n",
    "\n",
    "\n",
    "    # if we dont find the student, or the subtopic in the database, we will use the lowest level and proficiency by default\n",
    "    default_level = 1\n",
    "    default_proficiency = 1\n",
    "\n",
    "    # Access the student's data from the database\n",
    "    student_data = None\n",
    "    for student_entry in database[\"students\"]:\n",
    "        if student in student_entry:\n",
    "            student_data = student_entry[student]\n",
    "            break\n",
    "\n",
    "\n",
    "    if student_data is not None:\n",
    "        # Find the sub-topic information for the student\n",
    "        sub_topic_data = None\n",
    "        for entry in student_data:\n",
    "            if entry[\"sub_topic\"] == sub_topic:\n",
    "                sub_topic_data = entry\n",
    "                break\n",
    "\n",
    "    # Check if student exists in the database\n",
    "    if student_data is None:\n",
    "        print(\"student is not in database. They will be start at Level 1, Proficiency 1\")\n",
    "        return default_level, default_proficiency\n",
    "    # Check if sub-topic exists for the student\n",
    "    if sub_topic_data is None:\n",
    "        print(f\"student has not data for '{sub_topic}' in this database. They will be start at Level 1, Proficiency 1\")\n",
    "        return default_level, default_proficiency\n",
    "    else:\n",
    "        # Retrieve the level and proficiency scores\n",
    "        level = sub_topic_data[\"level\"]\n",
    "        proficiency = sub_topic_data[\"proficiency\"]\n",
    "\n",
    "    # Return the level and proficiency scores\n",
    "    return level, proficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "\n",
    "# 0 setting up database\n",
    "# database is currently 'students.json'\n",
    "\n",
    "# 1. make sure GPT only answers math questions\n",
    "def filter_answers():\n",
    "    message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"I am a math teacher for Grade K-12 in the United States. I am using the GPT API to help me answer my students' math questions. Please only answer my questions about math, and do not respond to any questions that are not about math.\"\n",
    "    }\n",
    "    return message\n",
    "# is_current_student: boolean\n",
    "def init_question(student, sub_topic):\n",
    "\n",
    "    level, proficiency = student_sub_topic_stats(student, sub_topic)\n",
    "        # criteria: tell GPT scales for proficiency and level\n",
    "\n",
    "    init = f\"Based on {student}'s database, the student's skill level for {sub_topic} is {level}. His level of proficiency for this level is {proficiency}. Please give {student} a test question based on {sub_topic} and follow up with a sentence like 'Explain how you got your answer'. Adjust the difficulty of the question based on his skill level and proficiency score. DO NOT include any other words. Do not put the answer in the prompt.\"\n",
    "    criteria = \"Proficiency is on a scale between 1 and 5, where 5 means the most proficient. Level is on a scale between 1 and 5, where 5 is the hardest level.\"\n",
    "\n",
    "    # combine criteria and message\n",
    "    message = f\"{init} {criteria}\"\n",
    "    init_crit = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": message\n",
    "    }\n",
    "\n",
    "    return init_crit\n",
    "\n",
    "def question_formatting()\n",
    "    pass\n",
    "\n",
    "\n",
    "# new student: student that is NOT in the database\n",
    "# is_current_student: boolean\n",
    "def ask_question(student, sub_topic):\n",
    "    # make sure to only receive math answers and initialize the questions GPT will give\n",
    "    filter_subject = filter_answers()\n",
    "    filter_question = init_question(student, sub_topic)\n",
    "    messages = [filter_subject,filter_question]\n",
    "    # print(messages)\n",
    "    res = get_response(messages)\n",
    "    tutor_question = res['choices'][0]['message']['content']\n",
    "    # here we print out the question GPT gives the student\n",
    "    print(f\"{tutor_question}: \\n\\n\")\n",
    "    return tutor_question\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T18:01:10.060328300Z",
     "start_time": "2023-07-13T18:01:10.042541700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student is not in database. They will be start at Level 1, Proficiency 1\n",
      "What is 3 + 2? Explain how you got your answer.: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'What is 3 + 2? Explain how you got your answer.'"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student = \"Jake\"\n",
    "topic = \"Addition of single digits\"\n",
    "ask_question(student, topic)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T18:04:54.702190200Z",
     "start_time": "2023-07-13T18:04:52.511488300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T17:07:30.357489700Z",
     "start_time": "2023-07-12T17:07:30.329453200Z"
    }
   },
   "outputs": [],
   "source": [
    "# check to see if the student has tried a subtopic\n",
    "def student_tried_sub_topic():\n",
    "    bool = False\n",
    "    return bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T13:47:40.324362100Z",
     "start_time": "2023-07-13T13:47:40.253547500Z"
    }
   },
   "outputs": [],
   "source": [
    "# time: time it took the student to answer the question given from GPT\n",
    "def grade_student_response(question, student_answer, student,time, sub_topic):\n",
    "    # take in the student's answer, and the topic\n",
    "    print(\"Answer: \\n\")\n",
    "    question_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"You are a math tutor. The question that the user is answering is '{question}'.\"\n",
    "\n",
    "    }\n",
    "    answer_explained = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"{student}'s answer is {student_answer}. Tell whether the student got the question correct and give and provide an explanation of the correct answer. Also explain where the student is incorrect\"\n",
    "    }\n",
    "    init_response_messages = [question_message,answer_explained]\n",
    "\n",
    "    answer_res = get_response_text(init_response_messages)\n",
    "    print(f\"{answer_res}\\n\\n\")\n",
    "\n",
    "\n",
    "    print(\"Evaluation: \\n\")\n",
    "    evaluation_messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"This is the question given to {student}: {question}. {student}'s answer is {student_answer}. THis is this is this is the answer you gave: {answer_res}.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"This I need you to evaluate {student}'s performance in terms of the following skill metrics: communication, interpretation, computation, conceptual, and the time taken to solve the question (it took the student {time} seconds to complete the question. For each of these metrics, rate the skill out of 5, where 5 out of 5 is the best score. make sure to have your evaluation in outline format. Also give an explanation on how {student} did not get the highest marks \"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"at the end, give an average score based on the above metrics\"\n",
    "        }\n",
    "    ]\n",
    "    evaluation_res = get_response_text(evaluation_messages)\n",
    "    print(evaluation_res)\n",
    "    print(\" \\n\\n\")\n",
    "    metrics_scores = extract_metrics_scores(evaluation_res)\n",
    "\n",
    "    # print(metrics_scores)\n",
    "    return  metrics_scores\n",
    "def extract_metrics_scores(text):\n",
    "    instruction = f\"Extract the metric numbers:\\n\\n{text}\\n\\n---\\n. Answer this question in the form of a JSON file\"\n",
    "    example_text = \"\"\"\n",
    "        Evaluation of Allan's Performance:\n",
    "\n",
    "        1. Communication: 4/5\n",
    "           - Allan effectively communicated his answer and explanation in a clear and concise manner. However, there could have been more elaboration and clarity in his explanation.\n",
    "\n",
    "        2. Interpretation: 5/5\n",
    "           - Allan correctly interpreted the given equation and understood the objective of isolating x.\n",
    "\n",
    "        3. Computation: 5/5\n",
    "           - Allan correctly performed the necessary computation steps to solve the equation and obtained the correct answer.\n",
    "\n",
    "        4. Conceptual Understanding: 4/5\n",
    "           - Allan demonstrated a good understanding of the concept of isolating x in an equation. However, his explanation could have included more conceptual details to further enhance his understanding.\n",
    "\n",
    "        5. Time Taken: 5/5\n",
    "           - Allan was able to solve the question in a relatively short amount of time, taking only 20 seconds.\n",
    "\n",
    "        Average Score: (4 + 5 + 5 + 4 + 5) / 5 = 4.6/5\n",
    "\n",
    "        Explanation:\n",
    "        Allan's performance was generally strong across all skill metrics. He effectively communicated his answer and demonstrated a good understanding of the concept. However, his explanation could have been more detailed and comprehensive, which affected his score in the communication and conceptual understanding categories. Overall, Allan performed well and achieved a high average score of 4.6 out of 5.\n",
    "        \"\"\"\n",
    "    example_res = \"\"\"\n",
    "        {\n",
    "            \"proficiency_metrics\": {\n",
    "                \"proficiency_avg\": 4.6,\n",
    "                \"communication\": {\n",
    "                    \"score\": 4,\n",
    "                    \"related_mistakes\": [\"could have been more elaboration and clarity in his explanation.\"]\n",
    "                },\n",
    "                \"interpretation\": {\n",
    "                    \"score\": 5,\n",
    "                    \"related_mistakes\": []\n",
    "                },\n",
    "                \"computation\": {\n",
    "                    \"score\": 5,\n",
    "                    \"related_mistakes\": []\n",
    "                },\n",
    "                \"conceptual\": {\n",
    "                    \"score\": 4,\n",
    "                    \"related_mistakes\": [\"explanation could have included more conceptual details to further enhance his understanding\"]\n",
    "                },\n",
    "                \"time\": {\n",
    "                    \"score\": 5,\n",
    "                    \"seconds\": 20\n",
    "                }\n",
    "            }\n",
    "    }\n",
    "    \"\"\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": example_text},\n",
    "        {\"role\": \"assistant\", \"content\": example_res}]\n",
    "\n",
    "    # get JSON data in form of response string\n",
    "    metric_scores_string =  get_response_text(messages)\n",
    "\n",
    "    # make the string a JSON\n",
    "\n",
    "    metric_scores_json = eval(metric_scores_string)\n",
    "    return metric_scores_json\n",
    "\n",
    "    # # print(metric_scores_json)\n",
    "    # return metric_scores_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scores_and_average(database_scores, new_score):\n",
    "\n",
    "    # the database stores the 3 most recent scores, so we will have to add our new_score and get rid of the old one\n",
    "\n",
    "    # add new score\n",
    "    # print(database_scores)\n",
    "    database_scores += [new_score]\n",
    "    # remove oldest score if there are more than 3 numbers in the list\n",
    "    if len(database_scores) > 3:\n",
    "        database_scores = database_scores[1:]\n",
    "\n",
    "# get the avg score and round to the last 2 decimals\n",
    "    new_avg_score = np.mean(database_scores)\n",
    "    new_avg_score = round(new_avg_score, 2)\n",
    "    return database_scores,new_avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T15:14:47.812869100Z",
     "start_time": "2023-07-13T15:14:47.801415700Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_level_update_needed(overall_avg_stats):\n",
    "    bool = False\n",
    "    avg_score, recent_scores =  overall_avg_stats[\"avg_score\"],overall_avg_stats[\"recent_scores\"]\n",
    "    # if the avg score is 5, and we have 3 scores that make up the average, we need a level update\n",
    "    if avg_score == 5 and len(recent_scores) == 3:\n",
    "        bool = True\n",
    "    return bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T17:48:50.395300700Z",
     "start_time": "2023-07-13T17:48:50.362465300Z"
    }
   },
   "outputs": [],
   "source": [
    "# update data for one person\n",
    "def update_data(data,metrics_updates):\n",
    "    metrics, level,questions_answered  =  data[\"proficiency_metrics\"], data[\"level\"],data[\"questions_answered\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # update metrics\n",
    "    metrics = update_metrics(metrics,metrics_updates)\n",
    "    # update level and questions_answered\n",
    "\n",
    "    # each index of the array corresponds to the amount of questions answered a a certain level of difficulty\n",
    "    questions_answered[level-1] += 1\n",
    "\n",
    "    # if we have to upgrade to the next level, we get rid of our previous level's stats\n",
    "    if is_level_update_needed(metrics[\"overall_avg\"]):\n",
    "        level += 1\n",
    "        print(f\"Congratulations, you have moved up to Level {level}\")\n",
    "        metrics = clear_metrics(metrics) # remove previous level's data\n",
    "\n",
    "\n",
    "    print(questions_answered)\n",
    "\n",
    "    return metrics,level,questions_answered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T17:42:48.840144600Z",
     "start_time": "2023-07-13T17:42:48.812287400Z"
    }
   },
   "outputs": [],
   "source": [
    "def clear_metrics(old_metrics):\n",
    "    metrics = {\n",
    "    \"overall_avg\": {\n",
    "        \"avg_score\": 0,\n",
    "        \"recent_scores\": [\n",
    "        ]\n",
    "    },\n",
    "    \"communication\": {\n",
    "        \"avg_score\": 0,\n",
    "        \"related_mistakes\": [\n",
    "        ],\n",
    "        \"recent_scores\": [\n",
    "        ]\n",
    "    },\n",
    "    \"interpretation\": {\n",
    "        \"avg_score\": 0,\n",
    "        \"related_mistakes\": [],\n",
    "        \"recent_scores\": []\n",
    "    },\n",
    "    \"computation\": {\n",
    "        \"avg_score\": 5.0,\n",
    "        \"related_mistakes\": [],\n",
    "        \"recent_scores\": []\n",
    "    },\n",
    "    \"conceptual\": {\n",
    "        \"avg_score\": 0,\n",
    "        \"related_mistakes\": [],\n",
    "        \"recent_scores\": []\n",
    "    },\n",
    "    \"time\": {\n",
    "        \"avg_score\": 0,\n",
    "        \"avg_times\": None,\n",
    "        \"recent_times\": [\n",
    "        ],\n",
    "        \"recent_scores\": [\n",
    "        ]\n",
    "    }}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T15:21:24.247165Z",
     "start_time": "2023-07-13T15:21:24.227000500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# updates the metrics for a \"proficiency_metrics\" value in the students.json. a metric_update is performed after each test\n",
    "def update_metrics(metrics, metric_updates):\n",
    "\n",
    "    metric_types = ['overall_avg', 'communication', 'interpretation', 'computation', 'conceptual', 'time']\n",
    "\n",
    "    for metric_type in metric_types:\n",
    "        metric, metric_update = metrics[metric_type], metric_updates[metric_type]\n",
    "\n",
    "        if metric_type == 'overall_avg':\n",
    "            new_score = metric_update\n",
    "        else:\n",
    "            new_score = metric_update['score']\n",
    "            if 'related_mistakes' in metric_update:\n",
    "                metric['related_mistakes'] = metric_update['related_mistakes']\n",
    "            if 'seconds' in metric_update:\n",
    "                new_time = metric_update['seconds']\n",
    "                metric['recent_times'], metric['avg_times'] = update_scores_and_average(metric['recent_times'], new_time)\n",
    "\n",
    "        metric['recent_scores'], metric['avg_score'] = update_scores_and_average(metric['recent_scores'], new_score)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T13:47:43.874275200Z",
     "start_time": "2023-07-13T13:47:43.841716100Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T17:43:03.800586500Z",
     "start_time": "2023-07-13T17:43:03.748137400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall_avg': {'avg_score': 4.8, 'recent_scores': [4.8]},\n",
       " 'communication': {'avg_score': 4.0,\n",
       "  'related_mistakes': ['needs to provide more examples'],\n",
       "  'recent_scores': [4]},\n",
       " 'interpretation': {'avg_score': 5.0,\n",
       "  'related_mistakes': [],\n",
       "  'recent_scores': [5]},\n",
       " 'computation': {'avg_score': 5.0,\n",
       "  'related_mistakes': [],\n",
       "  'recent_scores': [5]},\n",
       " 'conceptual': {'avg_score': 4.0,\n",
       "  'related_mistakes': [],\n",
       "  'recent_scores': [4]},\n",
       " 'time': {'avg_score': 5.0,\n",
       "  'avg_times': 30.0,\n",
       "  'recent_times': [30],\n",
       "  'recent_scores': [5]}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_update = {\n",
    "    \"overall_avg\": 4.8,\n",
    "    \"communication\": {\n",
    "        \"score\": 4,\n",
    "        \"related_mistakes\": [\"needs to provide more examples\"]\n",
    "    },\n",
    "    \"interpretation\": {\n",
    "        \"score\": 5,\n",
    "        \"related_mistakes\": []\n",
    "    },\n",
    "    \"computation\": {\n",
    "        \"score\": 5,\n",
    "        \"related_mistakes\": []\n",
    "    },\n",
    "    \"conceptual\": {\n",
    "        \"score\": 4,\n",
    "        \"related_mistakes\": []\n",
    "    },\n",
    "    \"time\": {\n",
    "        \"score\": 5,\n",
    "        \"seconds\": 30\n",
    "    }\n",
    "}\n",
    "\n",
    "database = {\"proficiency_metrics\": {\n",
    "    \"overall_avg\": {\n",
    "        \"avg_score\": 4,\n",
    "        \"recent_scores\": []\n",
    "    },\n",
    "    \"communication\": {\n",
    "        \"avg_score\": 4,\n",
    "        \"related_mistakes\": [\n",
    "            \"needs to provide more examples\"\n",
    "        ],\n",
    "        \"recent_scores\": []\n",
    "\n",
    "    },\n",
    "    \"interpretation\": {\n",
    "        \"avg_score\": 5,\n",
    "        \"related_mistakes\": [],\n",
    "        \"recent_scores\": []\n",
    "    },\n",
    "    \"computation\": {\n",
    "        \"avg_score\": 4,\n",
    "        \"related_mistakes\": [\"forgot to add 1\"],\n",
    "        \"recent_scores\": []\n",
    "    },\n",
    "    \"conceptual\": {\n",
    "        \"avg_score\": 4,\n",
    "        \"related_mistakes\": [],\n",
    "        \"recent_scores\": []\n",
    "    },\n",
    "    \"time\": {\n",
    "        \"avg_score\": 4,\n",
    "        \"avg_times\": 30,\n",
    "        \"recent_times\": [],\n",
    "        \"recent_scores\": []\n",
    "    }\n",
    "}}\n",
    "metrics = database[\"proficiency_metrics\"]\n",
    "update_metrics(metrics,metric_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T14:06:45.933696200Z",
     "start_time": "2023-07-13T14:06:45.918362900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T17:43:26.073407Z",
     "start_time": "2023-07-13T17:43:26.041067400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def update_student_stats(name, sub_topic, metric_updates):\n",
    "    # Get data from students.json\n",
    "    with open('students.json') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Check if the student is in the database\n",
    "    students = data[\"students\"]\n",
    "    for student in students:\n",
    "        if name in student:\n",
    "            # Check if the student has a section for the given subtopic\n",
    "            sections = student[name]\n",
    "            for section in sections:\n",
    "                if section[\"sub_topic\"] == sub_topic:\n",
    "                    # Update the student's metrics\n",
    "                    section[\"proficiency_metrics\"], section[\"level\"],section[\"questions_answered\"], = update_data(section,metric_updates)\n",
    "                    print(f\"{name}'s data metrics for '{sub_topic}'has been updated \")\n",
    "                    break\n",
    "            else:\n",
    "                # If the student does not have data for that subtopic, add updated_metrics\n",
    "                sections.append({\n",
    "                    \"sub_topic\": sub_topic,\n",
    "                    \"level\": 1,\n",
    "                    \"questions_answered\": [1,0,0,0,0],\n",
    "                    \"proficiency_metrics\": updated_metrics\n",
    "                })\n",
    "\n",
    "            break\n",
    "    else:\n",
    "        # If the student is not found in the database, create a new entry\n",
    "        students.append({\n",
    "            name: [{\n",
    "                \"sub_topic\": sub_topic,\n",
    "                \"level\": 1,\n",
    "                \"questions_answered\": [1,0,0,0,0],\n",
    "                \"proficiency_metrics\": updated_metrics\n",
    "            }]\n",
    "        })\n",
    "        print(f\"{name}'s data metrics for '{sub_topic}'has been added \")\n",
    "    # Write the updated data back to students.json\n",
    "    with open('students.json', 'w') as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T17:44:28.542586300Z",
     "start_time": "2023-07-13T17:44:28.522306900Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "updated_metrics = {\n",
    "    \"overall_avg\": 4,\n",
    "    \"communication\": {\n",
    "        \"score\": 4,\n",
    "        \"related_mistakes\": [\"needs to provide more examples\"]\n",
    "    },\n",
    "    \"interpretation\": {\n",
    "        \"score\": 5,\n",
    "        \"related_mistakes\": []\n",
    "    },\n",
    "    \"computation\": {\n",
    "        \"score\": 5,\n",
    "        \"related_mistakes\": []\n",
    "    },\n",
    "    \"conceptual\": {\n",
    "        \"score\": 4,\n",
    "        \"related_mistakes\":  [\"forgot to add 1\", \"forgot to simplify\"]\n",
    "    },\n",
    "    \"time\": {\n",
    "        \"score\": 2,\n",
    "        \"seconds\": 300\n",
    "    }\n",
    "}\n",
    "updated_metrics_2 = {\n",
    "    \"overall_avg\": 5,\n",
    "    \"communication\": {\n",
    "        \"score\": 5,\n",
    "        \"related_mistakes\": []\n",
    "    },\n",
    "    \"interpretation\": {\n",
    "        \"score\": 5,\n",
    "        \"related_mistakes\": []\n",
    "    },\n",
    "    \"computation\": {\n",
    "        \"score\": 5,\n",
    "        \"related_mistakes\": []\n",
    "    },\n",
    "    \"conceptual\": {\n",
    "        \"score\": 5,\n",
    "        \"related_mistakes\":  []\n",
    "    },\n",
    "    \"time\": {\n",
    "        \"score\": 5,\n",
    "        \"seconds\": 30\n",
    "    }\n",
    "}\n",
    "with open('students.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T17:49:04.542414500Z",
     "start_time": "2023-07-13T17:49:04.517346200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 9, 1, 0, 0]\n",
      "Alice's data metrics for 'Addition of two-digit numbers'has been updated \n"
     ]
    }
   ],
   "source": [
    "\n",
    "update_student_stats(\"Alice\", \"Addition of two-digit numbers\", updated_metrics_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T17:44:51.753290700Z",
     "start_time": "2023-07-13T17:44:51.748293100Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def update_student_stats_old(name, sub_topic, updated_metrics):\n",
    "    # Get data from students.json\n",
    "    with open('students.json') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Check if the student is in the database\n",
    "    students = data[\"students\"]\n",
    "    for student in students:\n",
    "        if name in student:\n",
    "            # Check if the student has a section for the given subtopic\n",
    "            sections = student[name]\n",
    "            for section in sections:\n",
    "                if section[\"sub_topic\"] == sub_topic:\n",
    "                    # Update the student's metrics\n",
    "                    metrics = section[\"proficiency_metrics\"]\n",
    "                    metrics[\"overall_avg\"][\"recent_avg_score\"] = updated_metrics[\"overall_avg\"]\n",
    "                    metrics[\"communication\"][\"recent_avg_score\"] = updated_metrics[\"communication\"][\"score\"]\n",
    "                    metrics[\"communication\"][\"related_mistakes\"] = updated_metrics[\"communication\"][\"related_mistakes\"]\n",
    "                    metrics[\"interpretation\"][\"recent_avg_score\"] = updated_metrics[\"interpretation\"][\"score\"]\n",
    "                    metrics[\"interpretation\"][\"related_mistakes\"] = updated_metrics[\"interpretation\"][\"related_mistakes\"]\n",
    "                    metrics[\"computation\"][\"recent_avg_score\"] = updated_metrics[\"computation\"][\"score\"]\n",
    "                    metrics[\"computation\"][\"related_mistakes\"] = updated_metrics[\"computation\"][\"related_mistakes\"]\n",
    "                    metrics[\"conceptual\"][\"rolling_avg_score\"] = updated_metrics[\"conceptual\"][\"score\"]\n",
    "                    metrics[\"conceptual\"][\"related_mistakes\"] = updated_metrics[\"conceptual\"][\"related_mistakes\"]\n",
    "                    metrics[\"time\"][\"recent_avg_score\"] = updated_metrics[\"time\"][\"score\"]\n",
    "                    metrics[\"time\"][\"seconds\"] = updated_metrics[\"time\"][\"seconds\"]\n",
    "                    print(f\"{name}'s data metrics for '{sub_topic}' has been updated\")\n",
    "                    break\n",
    "            else:\n",
    "                # If the student does not have data for that subtopic, add updated_metrics\n",
    "                sections.append({\n",
    "                    \"sub_topic\": sub_topic,\n",
    "                    \"proficiency_metrics\": updated_metrics\n",
    "                })\n",
    "\n",
    "            break\n",
    "    else:\n",
    "        # If the student is not found in the database, create a new entry\n",
    "        students.append({\n",
    "            name: [{\n",
    "                \"sub_topic\": sub_topic,\n",
    "                \"proficiency_metrics\": updated_metrics\n",
    "            }]\n",
    "        })\n",
    "        print(f\"{name}'s data metrics for '{sub_topic}' has been added\")\n",
    "\n",
    "    # Write the updated data back to students.json\n",
    "    with open('students.json', 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:29:15.731051500Z",
     "start_time": "2023-07-11T15:29:11.164146100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'proficiency_metrics': {'communication': {'score': 4,\n",
       "   'related_mistakes': ['could have been more elaboration and clarity in his explanation.']},\n",
       "  'interpretation': {'score': 5, 'related_mistakes': []},\n",
       "  'computation': {'score': 5, 'related_mistakes': []},\n",
       "  'conceptual': {'score': 4,\n",
       "   'related_mistakes': ['explanation could have included more conceptual details to further enhance his understanding']},\n",
       "  'time_taken': {'score': 5, 'seconds': 20}},\n",
       " 'average_score': 4.6}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ans = \"\"\"\n",
    "Evaluation of Allan's Performance:\n",
    "\n",
    "1. Communication: 4/5\n",
    "   - Allan effectively communicated his solution by providing a clear explanation of the steps taken to solve the equation.\n",
    "\n",
    "2. Interpretation: 5/5\n",
    "   - Allan correctly interpreted the given equation and understood that the goal was to find the value of x.\n",
    "\n",
    "3. Computation: 4/5\n",
    "   - Allan correctly divided both sides of the equation by 2 to isolate x. However, he made a mistake in simplifying 8/2 to 4 instead of 8/2 = 4.\n",
    "\n",
    "4. Conceptual: 4/5\n",
    "   - Allan demonstrated a good understanding of the concept of isolating variables in equations. However, he made a mistake in simplifying the equation, which indicates a slight gap in conceptual understanding.\n",
    "\n",
    "5. Time taken: 5/5\n",
    "   - Allan was able to solve the question in a relatively short amount of time, taking only 20 seconds.\n",
    "\n",
    "Average Score: (4 + 5 + 4 + 4 + 5) / 5 = 4.4/5\n",
    "\n",
    "Explanation:\n",
    "Allan's overall performance is commendable, with a strong understanding of the interpretation and computation aspects of the question. However, he made a mistake in the simplification step, which affected his conceptual understanding and computation accuracy. This slight error prevented him from achieving the highest marks in all skill metrics.\n",
    "\n",
    "\n",
    "\n",
    "Based on the evaluation, Allan's overall performance is strong with an average score of 4.6 out of 5. He excelled in interpretation, computation, and time management. However, there are areas for improvement in communication and conceptual understanding. Allan could have provided more elaboration and clarity in his explanation, and his conceptual explanation could have been more detailed. Overall, Allan demonstrated a good understanding of the concept and was able to solve the problem efficiently.\n",
    "\"\"\"\n",
    "\n",
    "test_dict = \"\"\"\n",
    "        {\n",
    "            \"proficiency_metrics\": {\n",
    "                \"proficiency_avg\": 4.6,\n",
    "                \"communication\": {\n",
    "                    \"score\": 4,\n",
    "                    \"related_mistakes\": [\"could have been more elaboration and clarity in his explanation.\"]\n",
    "                },\n",
    "                \"interpretation\": {\n",
    "                    \"score\": 5,\n",
    "                    \"related_mistakes\": []\n",
    "                },\n",
    "                \"computation\": {\n",
    "                    \"score\": 5,\n",
    "                    \"related_mistakes\": []\n",
    "                },\n",
    "                \"conceptual\": {\n",
    "                    \"score\": 4,\n",
    "                    \"related_mistakes\": [\"explanation could have included more conceptual details to further enhance his understanding\"]\n",
    "                },\n",
    "                \"time\": {\n",
    "                    \"score\": 5,\n",
    "                    \"seconds\": 20\n",
    "                }\n",
    "            }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "test_dict = extract_metrics_scores(test_ans)\n",
    "\n",
    "type(test_dict)\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:14:08.700299600Z",
     "start_time": "2023-07-11T15:14:03.755030800Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T15:14:57.295883600Z",
     "start_time": "2023-07-11T15:14:57.278196200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'proficiency_metrics': {'communication': {'score': 4,\n",
       "   'related_mistakes': ['could have been more elaboration and clarity in his explanation.']},\n",
       "  'interpretation': {'score': 5, 'related_mistakes': []},\n",
       "  'computation': {'score': 5, 'related_mistakes': []},\n",
       "  'conceptual': {'score': 4,\n",
       "   'related_mistakes': ['explanation could have included more conceptual details to further enhance his understanding']},\n",
       "  'time_taken': {'score': 5, 'seconds': 20}},\n",
       " 'average_score': 4.6}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T12:45:47.697539100Z",
     "start_time": "2023-07-11T12:45:47.661637600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[84], line 10\u001B[0m\n\u001B[0;32m      1\u001B[0m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproficiency_metrics\u001B[39m\u001B[38;5;124m'\u001B[39m: {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcommunication\u001B[39m\u001B[38;5;124m'\u001B[39m: {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m4\u001B[39m,\n\u001B[0;32m      2\u001B[0m                                            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelated_mistakes\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcould have been more elaboration and clarity in his explanation.\u001B[39m\u001B[38;5;124m'\u001B[39m]},\n\u001B[0;32m      3\u001B[0m                          \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minterpretation\u001B[39m\u001B[38;5;124m'\u001B[39m: {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m5\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelated_mistakes\u001B[39m\u001B[38;5;124m'\u001B[39m: []},\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      7\u001B[0m                          \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime_taken\u001B[39m\u001B[38;5;124m'\u001B[39m: {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m5\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mseconds\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m20\u001B[39m}},\n\u001B[0;32m      8\u001B[0m  \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maverage_score\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m4.6\u001B[39m}\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m({test_dict}))\n\u001B[1;32m---> 10\u001B[0m \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m json\u001B[38;5;241m.\u001B[39mdumps(b)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cuda_env\\lib\\json\\__init__.py:293\u001B[0m, in \u001B[0;36mload\u001B[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[0;32m    274\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(fp, \u001B[38;5;241m*\u001B[39m, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, object_hook\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, parse_float\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    275\u001B[0m         parse_int\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, parse_constant\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, object_pairs_hook\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw):\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001B[39;00m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;124;03m    a JSON document) to a Python object.\u001B[39;00m\n\u001B[0;32m    278\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001B[39;00m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loads(\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m(),\n\u001B[0;32m    294\u001B[0m         \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcls\u001B[39m, object_hook\u001B[38;5;241m=\u001B[39mobject_hook,\n\u001B[0;32m    295\u001B[0m         parse_float\u001B[38;5;241m=\u001B[39mparse_float, parse_int\u001B[38;5;241m=\u001B[39mparse_int,\n\u001B[0;32m    296\u001B[0m         parse_constant\u001B[38;5;241m=\u001B[39mparse_constant, object_pairs_hook\u001B[38;5;241m=\u001B[39mobject_pairs_hook, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type({test_dict}))\n",
    "json.load(test_dict)\n",
    "json.dumps(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T12:25:39.441354800Z",
     "start_time": "2023-07-11T12:25:24.046546100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "\n",
      "The student's answer is incorrect. The correct answer is x = 4. \n",
      "\n",
      "To solve the equation 2x = 8, we need to isolate x. \n",
      "\n",
      "Dividing both sides of the equation by 2, we get:\n",
      "\n",
      "(2x)/2 = 8/2\n",
      "\n",
      "Simplifying, we have:\n",
      "\n",
      "x = 4\n",
      "\n",
      "Therefore, the correct answer is x = 4. The student incorrectly stated that 8/2 = 4, which is not true. The correct simplification is 8/2 = 4.\n",
      "\n",
      "\n",
      "Evaluation: \n",
      "\n",
      "Evaluation of Allan's Performance:\n",
      "\n",
      "1. Communication: 4/5\n",
      "   - Allan effectively communicated his solution by providing a clear explanation of the steps taken to solve the equation.\n",
      "\n",
      "2. Interpretation: 5/5\n",
      "   - Allan correctly interpreted the given equation and understood that the goal was to find the value of x.\n",
      "\n",
      "3. Computation: 4/5\n",
      "   - Allan correctly divided both sides of the equation by 2 to isolate x. However, he made a mistake in simplifying 8/2 as 4 instead of 8/2 = 4.\n",
      "\n",
      "4. Conceptual Understanding: 4/5\n",
      "   - Allan demonstrated a good understanding of the concept of isolating variables in equations. However, he made a mistake in simplifying the division.\n",
      "\n",
      "5. Time Taken: 5/5\n",
      "   - Allan was able to solve the question in a relatively short amount of time, taking only 20 seconds.\n",
      "\n",
      "Average Score: (4 + 5 + 4 + 4 + 5) / 5 = 4.4/5\n",
      "\n",
      "Explanation:\n",
      "Allan's overall performance was quite good, with a strong understanding of the concept and effective communication. However, he made a mistake in the computation step, which affected his final answer. This error resulted in a slightly lower score in the computation and conceptual understanding metrics. Nonetheless, Allan's performance was still above average, with an average score of 4.4 out of 5.\n",
      " \n",
      "\n",
      "\n",
      "{'proficiency_metrics': {'communication': {'score': 4, 'related_mistakes': ['could have been more elaboration and clarity in his explanation.']}, 'interpretation': {'score': 5, 'related_mistakes': []}, 'computation': {'score': 5, 'related_mistakes': []}, 'conceptual_understanding': {'score': 4, 'related_mistakes': ['explanation could have included more conceptual details to further enhance his understanding']}, 'time_taken': {'score': 5, 'seconds': 20}}, 'average_score': 4.6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'proficiency_metrics': {'communication': {'score': 4,\n",
       "   'related_mistakes': ['could have been more elaboration and clarity in his explanation.']},\n",
       "  'interpretation': {'score': 5, 'related_mistakes': []},\n",
       "  'computation': {'score': 5, 'related_mistakes': []},\n",
       "  'conceptual_understanding': {'score': 4,\n",
       "   'related_mistakes': ['explanation could have included more conceptual details to further enhance his understanding']},\n",
       "  'time_taken': {'score': 5, 'seconds': 20}},\n",
       " 'average_score': 4.6}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "q,sa,s,t,st = \"if 2x = 8, x = ?\", \"x = 4, because 8/2 = 2x/2, when we simplify, we get x = 4, because 8/2 = 4\", \"Allan\", \"20 seconds\", \"prealgebra variables\"\n",
    "\n",
    "grade_student_response(q,sa,s,t,st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T12:12:17.251105500Z",
     "start_time": "2023-07-11T12:12:17.223658700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'proficiency_metrics': {'proficiency_avg': 4.6, 'communication': {'score': 4, 'related_mistakes': ['could have been more elaboration and clarity in his explanation.']}, 'interpretation': {'score': 5, 'related_mistakes': []}, 'computation': {'score': 5, 'related_mistakes': []}, 'conceptual': {'score': 4, 'related_mistakes': ['explanation could have included more conceptual details to further enhance his understanding']}, 'time': {'score': 5, 'seconds': 20}}}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T18:02:03.292287400Z",
     "start_time": "2023-07-06T18:02:03.275427200Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# gets the students score\n",
    "# def get_score(evaluation, topic):\n",
    "#     messages = [{\n",
    "#         \"role\": \"system\",\n",
    "#         \"content\": f\"Based on the provided text, what grade on a scale of 1 to 5 did the student receive for {topic}? If the student goes not submit a score, give the student a score of 1. Make sure to only give one digit as your response: {evaluation}. \"\n",
    "#     }]\n",
    "#     res = get_response(messages)\n",
    "#     grade = res['choices'][0]['message']['content']\n",
    "#     # the grade is a string, so we convert the rating into an integer\n",
    "#     print(f\"updated skill level: {grade}\")\n",
    "#     return int(grade)\n",
    "\n",
    "def update_student_stats(name, sub_topic, updated_metrics):\n",
    "    # Get data from students.json\n",
    "    with open('students.json') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Flag to check if student is found\n",
    "    student_found = False\n",
    "\n",
    "    # Search for the student by name\n",
    "    for student in data['students']:\n",
    "        # find the student\n",
    "        if name in student:\n",
    "            student_found = True\n",
    "            # Find the topic in the student's records\n",
    "            topic_found = False\n",
    "            for record in student[name]:\n",
    "                if record['topic'] == topic:\n",
    "                    # Update the understandingLevel score\n",
    "                    record['understandingLevel'] = updated_skill\n",
    "                    print(f'Updated understanding level for topic: {topic} to {updated_skill}')\n",
    "                    topic_found = True\n",
    "                    break  # No need to continue searching\n",
    "\n",
    "            # If the topic was not found, add a new record for the topic\n",
    "            if not topic_found:\n",
    "                student[name].append({'topic': topic, 'understandingLevel': updated_skill})\n",
    "                print(f'Added new record for topic: {topic} for student {name}')\n",
    "\n",
    "    # If the student was not found, add a new student with the record\n",
    "    if not student_found:\n",
    "        data['students'].append({name: [{'topic': topic, 'understandingLevel': updated_skill}]})\n",
    "        print(f'Added new student {name} with record for topic {topic}')\n",
    "\n",
    "    # Write the updated data back to the file\n",
    "    with open('students.json', 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print('Saved updated data to students.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T17:47:57.453570500Z",
     "start_time": "2023-07-06T17:47:57.436733600Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns\n",
    "#   - the response the student gives\n",
    "#   - the time it takes to get a response form the studnet\n",
    "def get_student_response():\n",
    "    start_time = time.time()\n",
    "\n",
    "    student_res = input() # response to question\n",
    "\n",
    "    end_time =  time.time()\n",
    "    end_time = end_time - start_time\n",
    "\n",
    "    return student_res, end_time\n",
    "\n",
    "def get_sub_topic(topic, subtopic, skill_level):\n",
    "    pass\n",
    "\n",
    "#TODO take into account students past experience when doing feedback\n",
    "\n",
    "#TODO fix get_score() function\n",
    "# TODO restart score when over 5 ( you can use x mod 5 + 1)\n",
    "#TODO use previous performance\n",
    "\n",
    "# TODO make a test portion\\\n",
    "# TODO how to update score based on previous experience\n",
    "\n",
    "# TODO make test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-06T17:40:54.338593700Z",
     "start_time": "2023-07-06T17:40:54.319462100Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2378614512.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[1], line 2\u001B[1;36m\u001B[0m\n\u001B[1;33m    def get_sub_topic(topic, subtopic, skill_level):\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mIndentationError\u001B[0m\u001B[1;31m:\u001B[0m expected an indented block\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T10:55:49.310447400Z",
     "start_time": "2023-07-11T10:55:49.289274900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T04:50:39.237877900Z",
     "start_time": "2023-06-28T04:50:39.229360700Z"
    }
   },
   "outputs": [],
   "source": [
    "# tests and old funcitons\n",
    "\n",
    "# topic examples\n",
    "topic1 = \"subtraction of two-digit numbers\"\n",
    "topic2 = \"Addition of two-digit numbers\"\n",
    "def add_new_student(name):\n",
    "    # get data from students.json\n",
    "    with open('students.json') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "# adds student to JSON database\n",
    "    new_student_json = {\n",
    "            f\"{name}\" : [\n",
    "\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # add new empty student to json\n",
    "    data['students'].append(new_student_json)\n",
    "    # Write the updated data back to the students.json file\n",
    "    with open('students.json', 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    print(f\"student '{name}' is added to the database\")\n",
    "def test1():\n",
    "    t = \"subtraction of two-digit numbers\"\n",
    "    q = \"What is 67 minus 32? Explain how you got your answer.\"\n",
    "    sa = \"My student's answer is '35 because 60 + 7 - 30 - 2 = 35'. if the scale is from 1 to 5, please grade his skill on subtraction ot two-digit numbers.\"\n",
    "    grade_student_response(q, sa, t)\n",
    "def test2():\n",
    "    test_eval = \"On a scale of 1 to 5, I would grade your student's skill on subtraction of two-digit numbers as a 3. While they have correctly subtracted the tens and ones place values, their explanation of how they got their answer is a little convoluted.\\n\\nThe actual answer to the problem of 'What is 67 minus 32?' is 35. To get this answer, you would subtract the ones place value (7-2 = 5) and then the tens place value (6-3=3). This gives you 35 as the difference between the two numbers.\\n\\nYour student's answer is correct but their explanation involves adding 60 and 7 before subtracting 30 and 2, which isn't necessary for this problem. It's important for your student to understand the steps in subtraction and use them consistently, avoiding unnecessary steps.\"\n",
    "\n",
    "    get_score(test_eval)\n",
    "def update_metrics_old(metrics, metric_updates):\n",
    "\n",
    "\n",
    "    metric_type = \"overall_avg\"\n",
    "    metric, metric_update = metrics[metric_type], metric_updates[metric_type]\n",
    "    new_score = metric_update\n",
    "    metric[\"recent_scores\"], metric[\"avg_score\"] = update_scores_and_average(metric[\"recent_scores\"], new_score)\n",
    "\n",
    "    metric_type = \"communication\"\n",
    "    metric, metric_update = metrics[metric_type], metric_updates[metric_type]\n",
    "    new_score = metric_update[\"score\"]\n",
    "    metric[\"recent_scores\"], metric[\"avg_score\"] = update_scores_and_average(metric[\"recent_scores\"], new_score)\n",
    "    metric[\"related_mistakes\"] = metric_update[\"related_mistakes\"]\n",
    "\n",
    "    metric_type = \"interpretation\"\n",
    "    metric, metric_update = metrics[metric_type], metric_updates[metric_type]\n",
    "    new_score = metric_update[\"score\"]\n",
    "    metric[\"recent_scores\"], metric[\"avg_score\"] = update_scores_and_average(metric[\"recent_scores\"], new_score)\n",
    "    metric[\"related_mistakes\"] = metric_update[\"related_mistakes\"]\n",
    "\n",
    "    metric_type = \"computation\"\n",
    "    metric, metric_update = metrics[metric_type], metric_updates[metric_type]\n",
    "    new_score = metric_update[\"score\"]\n",
    "    metric[\"recent_scores\"], metric[\"avg_score\"] = update_scores_and_average(metric[\"recent_scores\"], new_score)\n",
    "    metric[\"related_mistakes\"] = metric_update[\"related_mistakes\"]\n",
    "\n",
    "    metric_type = \"conceptual\"\n",
    "    metric, metric_update = metrics[metric_type], metric_updates[metric_type]\n",
    "    new_score = metric_update[\"score\"]\n",
    "    metric[\"recent_scores\"], metric[\"rolling_avg_score\"] = update_scores_and_average(metric[\"recent_scores\"], new_score)\n",
    "    metric[\"related_mistakes\"] = metric_update[\"related_mistakes\"]\n",
    "\n",
    "    metric_type = \"time\"\n",
    "    metric, metric_update = metrics[metric_type], metric_updates[metric_type]\n",
    "    new_score = metric_update[\"score\"]\n",
    "    new_time =  metric_update[\"seconds\"]\n",
    "    metric[\"recent_scores\"], metric[\"avg_score\"] = update_scores_and_average(metric[\"recent_scores\"], new_score)\n",
    "    # update second average and scores\n",
    "    metric[\"recent_times\"], metric[\"avg_times\"] = update_scores_and_average(metric[\"recent_times\"], new_time)\n",
    "    # add the\n",
    "\n",
    "    # else:\n",
    "    #     raise ValueError(f\"Unknown metric type: {metric_type}\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:41:27.061655200Z",
     "start_time": "2023-06-28T06:41:27.054654600Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Code to be executed when the script is run directly\n",
    "    # ask the student information before asking them questions\n",
    "    name = input(\"What is your name: \")\n",
    "    grade = input(\"What grade are you in: \")\n",
    "    student_in_database = check_student_in_database()\n",
    "    topic = input(\"What topic do you want to practice: \")\n",
    "    current_skill = input(f\"What is your current skill level for the topic: {topic}, between 1 and 5, with 5 being the most knowledgable: \")\n",
    "\n",
    "    while True:\n",
    "        # GPT gives the student a question\n",
    "        question = ask_question(grade,topic,student_in_database,name,current_skill)\n",
    "\n",
    "        # student answers said questions\n",
    "        student_answer = input(question)\n",
    "\n",
    "        tutor_response = grade_student_response(question,student_answer,topic)\n",
    "\n",
    "        updated_skill = get_score(tutor_response, topic)\n",
    "        update_student_stats(name, topic, updated_skill)\n",
    "\n",
    "        # if the student wants more questions, we will make sure that they will get questions based on their newly defined skill level\n",
    "        current_skill = updated_skill\n",
    "        want_question = input(\"would you want to be asked another question, type 'yes' or 'no'\")\n",
    "        if want_question == \"no\":\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T06:43:40.551801400Z",
     "start_time": "2023-06-28T06:41:29.803113300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of a variable is x + 5 = 10. Explain how you got your answer.\n",
      "\n",
      "\n",
      "The equation you provided, x + 5 = 10, is an example of an algebraic equation with a variable. In this case, the variable is represented by 'x'.\n",
      "\n",
      "To solve for the value of 'x', we need to isolate it on one side of the equation. We can do this by performing the same operation on both sides of the equation to maintain equality.\n",
      "\n",
      "Starting with x + 5 = 10, we can subtract 5 from both sides:\n",
      "\n",
      "x + 5 - 5 = 10 - 5\n",
      "\n",
      "This simplifies to:\n",
      "\n",
      "x = 5\n",
      "\n",
      "So, the correct answer is x = 5. Your student's answer is correct.\n",
      "\n",
      "Based on the provided solution and understanding of variables in this context, I would grade your student's skill level with variables as a 3.\n",
      "\n",
      "\n",
      "updated skill level: 3\n",
      "Added new student Jill with record for topic variables\n",
      "Saved updated data to students.json\n",
      "Example: Bob has 5 apples. How many apples does Alice have? Explain how you got your answer.\n",
      "\n",
      "\n",
      "The actual answer to the question \"Example: Bob has 5 apples. How many apples does Alice have?\" cannot be determined with the information provided. The question does not provide any information or relationship between Bob and Alice regarding their apple ownership. Therefore, we cannot conclude the quantity of apples Alice has based solely on Bob's number.\n",
      "\n",
      "As for the user's response, it is incorrect. The answer of 5 suggests that Alice has the same number of apples as Bob because they are married. However, this is an assumption that goes beyond the given information and does not follow logical reasoning.\n",
      "\n",
      "Regarding the user's skill in handling variables, based on this specific answer, I would grade it as a 2.\n",
      "\n",
      "\n",
      "updated skill level: 1\n",
      "Updated understanding level for topic: variables to 1\n",
      "Saved updated data to students.json\n"
     ]
    }
   ],
   "source": [
    "# Check if the script is being run directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
